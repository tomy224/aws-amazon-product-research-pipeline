#!/usr/bin/env python
# coding: utf-8

"""
Keepa APIã‚’ä½¿ç”¨ã—ã¦å•†å“æƒ…å ±ã‚’1ASINãšã¤å–å¾—ãƒ»åˆ†æã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€Keepa APIã‚’ä½¿ç”¨ã—ã¦å•†å“æƒ…å ±ã‚’1ASINãšã¤å–å¾—ãƒ»åˆ†æã—ã¾ã™ã€‚
ãƒãƒƒãƒå‡¦ç†ã§ã¯ãªãå˜ä¸€ASINå‡¦ç†ã«ç‰¹åŒ–ã—ã¦ãŠã‚Šã€AWS Lambdaãªã©ã®ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ç’°å¢ƒã«é©ã—ã¦ã„ã¾ã™ã€‚
"""

import keepa
import pandas as pd
from datetime import datetime
import logging
import os
import yaml
from pathlib import Path
import dotenv
import traceback
import time

from modules.utils.logger_utils import get_logger, log_function_call
from modules.utils.file_utils import find_project_root, load_yaml_config, save_to_csv

# ãƒ­ã‚¬ãƒ¼ã®å–å¾—
logger = get_logger(__name__)

class BaseKeepaAPISingle:
    """
    Keepa APIã¨ã®é€šä¿¡ã‚„åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’è¡Œã†ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹ï¼ˆ1ASINãšã¤å‡¦ç†ï¼‰
    
    ã“ã®ã‚¯ãƒ©ã‚¹ã¯ã€Keepa APIã®åˆæœŸåŒ–ã€APIå‘¼ã³å‡ºã—ï¼ˆå˜ä¸€ASINï¼‰ã€åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’æ‹…å½“ã—ã¾ã™ã€‚
    """
    
    def __init__(self, config_path=None):
        """
        BaseKeepaAPISingleã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        
        Args:
            config_path (str, optional): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰
        """
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œå‡º
        self.root_dir = find_project_root()
        
        # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
        dotenv.load_dotenv(os.path.join(self.root_dir, '.env'))
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®è¨­å®š
        self.data_dir = os.path.join(self.root_dir, 'data')
        self.log_dir = os.path.join(self.root_dir, 'logs')
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.log_dir, exist_ok=True)
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        self.config = self._load_config(config_path)
        
        try:
            # Keepa APIã®åˆæœŸåŒ–ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ãŸAPIã‚­ãƒ¼ã‚’ä½¿ç”¨ï¼‰
            api_key = os.getenv('KEEPA_API_KEY') or self.config['keepa_api'].get('api_key')
            if not api_key:
                raise ValueError("KEEPA_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
                
            self.api = keepa.Keepa(api_key, timeout=60)  # å˜ä¸€ASINã®å ´åˆã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’60ç§’ã«è¨­å®š
            logger.info("Keepa APIã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸ")
        except Exception as e:
            logger.error(f"Keepa APIã®åˆæœŸåŒ–ã«å¤±æ•—: {str(e)}")
            raise
    
    def _load_config(self, config_path=None):
        """
        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            config_path (str, optional): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            dict: è¨­å®šãƒ‡ãƒ¼ã‚¿
        """
        if config_path is None:
            config_path = os.path.join(self.root_dir, 'config', 'settings.yaml')
            
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                
            # Keepa APIè¨­å®šã®å­˜åœ¨ç¢ºèª
            if 'keepa_api' not in config:
                raise ValueError("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«keepa_apiã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
            # å‡ºåŠ›è¨­å®šã®åˆæœŸåŒ–ï¼ˆãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼‰
            if 'output' not in config['keepa_api']:
                config['keepa_api']['output'] = {
                    'input_file': os.path.join(self.data_dir, 'sp_api_output_filtered.csv'),
                    'output_file': os.path.join(self.data_dir, 'keepa_output_single.csv')
                }
            else:
                # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                for key in ['input_file', 'output_file']:
                    if key in config['keepa_api']['output']:
                        rel_path = config['keepa_api']['output'][key]
                        if not os.path.isabs(rel_path):
                            config['keepa_api']['output'][key] = os.path.join(self.data_dir, rel_path)
                    
            logger.info(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸ: {config_path}")
            return config
                
        except Exception as e:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}")
            raise
    
    @log_function_call
    def _call_api_single(self, asin):
        """
        Keepa APIã‚’å‘¼ã³å‡ºã—ã¦å˜ä¸€ASINã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ã¨ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ä»˜ãï¼‰
        
        Args:
            asin (str): å˜ä¸€ã®ASIN
        
        Returns:
            list or None: Keepa APIã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
        """
        MAX_RETRIES = 3  # æœ€å¤§å†è©¦è¡Œå›æ•°
        
        for retry in range(MAX_RETRIES):
            try:
                # APIå‘¼ã³å‡ºã—å‰ã«ãƒˆãƒ¼ã‚¯ãƒ³æ®‹é‡ã‚’ç¢ºèª
                tokens_left = self.api.tokens_left
                logger.info(f"APIå‘¼ã³å‡ºã—å‰ã®ãƒˆãƒ¼ã‚¯ãƒ³æ®‹é‡: {tokens_left} (ASIN: {asin})")
                
                # å¿…è¦ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—ï¼ˆASINã‚ãŸã‚Šç´„1ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ï¼‰
                estimated_tokens = 1  # å˜ä¸€ASINã®å‡¦ç†ãªã®ã§1ãƒˆãƒ¼ã‚¯ãƒ³
                
                # ãƒˆãƒ¼ã‚¯ãƒ³ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ä¸­æ­¢
                if tokens_left < estimated_tokens or tokens_left <= 0:
                    error_msg = f"ãƒˆãƒ¼ã‚¯ãƒ³ä¸è¶³ã®ãŸã‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚æ®‹ãƒˆãƒ¼ã‚¯ãƒ³: {tokens_left}ã€å¿…è¦ãƒˆãƒ¼ã‚¯ãƒ³: {estimated_tokens} (ASIN: {asin})"
                    logger.error(error_msg)
                    print(f"âŒ {error_msg}")
                    return None
                
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã‚’å¤‰æ›´
                if hasattr(self.api, 'session') and hasattr(self.api.session, 'request'):
                    # å…ƒã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                    original_request = self.api.session.request
                    
                    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–¢æ•°ã§ç½®ãæ›ãˆ
                    def request_with_timeout(*args, **kwargs):
                        kwargs['timeout'] = 30  # 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                        return original_request(*args, **kwargs)
                    
                    # ä¸€æ™‚çš„ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç½®ãæ›ãˆ
                    self.api.session.request = request_with_timeout
                
                # APIå‘¼ã³å‡ºã—ï¼ˆå˜ä¸€ASINãªã®ã§ãƒªã‚¹ãƒˆã«åŒ…ã‚€ï¼‰
                products = self.api.query(
                    [asin],  # ãƒªã‚¹ãƒˆã¨ã—ã¦æ¸¡ã™
                    domain=self.config['keepa_api'].get('domain', 5),    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ—¥æœ¬ï¼ˆ5ï¼‰
                    stats=self.config['keepa_api'].get('stats_days', 180),  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯180æ—¥
                    days=self.config['keepa_api'].get('stats_days', 180),
                    update=1
                )
                
                # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã‚’å…ƒã«æˆ»ã™
                if hasattr(self.api, 'session') and hasattr(self.api.session, 'request'):
                    self.api.session.request = original_request
                
                # å‘¼ã³å‡ºã—å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³æ®‹é‡ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
                tokens_after = self.api.tokens_left
                tokens_used = tokens_left - tokens_after
                logger.info(f"APIå‘¼ã³å‡ºã—å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³æ®‹é‡: {tokens_after} (æ¶ˆè²»: {tokens_used}) (ASIN: {asin})")
                
                # çµæœã®ç¢ºèª
                if products:
                    logger.info(f"APIå‘¼ã³å‡ºã—æˆåŠŸ: {len(products)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— (ASIN: {asin})")
                    return products
                else:
                    logger.warning(f"APIå‘¼ã³å‡ºã—çµæœãŒç©ºã§ã™ï¼ˆè©¦è¡Œ {retry+1}/{MAX_RETRIES}ï¼‰ (ASIN: {asin})")
                    
            except Exception as e:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’ç¢ºèª
                if "timeout" in str(e).lower() or "read timed out" in str(e).lower():
                    logger.warning(f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆè©¦è¡Œ {retry+1}/{MAX_RETRIES}ï¼‰ (ASIN: {asin}): {str(e)}")
                    # æœ€çµ‚è©¦è¡Œã§ãªã‘ã‚Œã°å†è©¦è¡Œ
                    if retry < MAX_RETRIES - 1:
                        wait_time = (retry + 1) * 5  # å†è©¦è¡Œã”ã¨ã«å¾…æ©Ÿæ™‚é–“ã‚’é•·ãã™ã‚‹
                        logger.info(f"{wait_time}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™... (ASIN: {asin})")
                        print(f"â±ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™... (ASIN: {asin})")
                        time.sleep(wait_time)
                        continue
                
                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
                logger.error(f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ (ASIN: {asin}): {str(e)}")
                print(f"âŒ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ (ASIN: {asin}): {str(e)}")
                return None
        
        # ã™ã¹ã¦ã®å†è©¦è¡ŒãŒå¤±æ•—ã—ãŸå ´åˆ
        logger.error(f"{MAX_RETRIES}å›ã®è©¦è¡Œå¾Œã‚‚APIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ (ASIN: {asin})")
        return None
    
    @staticmethod
    def safe_get(data, *keys, default=None):
        """
        åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å–å¾—ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
        
        Args:
            data: å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ï¼ˆdict or listï¼‰
            *keys: é †ç•ªã«å–å¾—ã™ã‚‹ã‚­ãƒ¼
            default: å–å¾—ã§ããªã‹ã£ãŸå ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
        Returns:
            å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        """
        for key in keys:
            try:
                data = data[key]
            except (KeyError, TypeError, IndexError):
                return default
        return data
    
    @log_function_call
    def load_asins_from_csv(self, input_file=None, asin_column='ASIN'):
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ASINãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            input_file (str, optional): å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆçœç•¥æ™‚ã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä½¿ç”¨ï¼‰
            asin_column (str): ASINåˆ—ã®åå‰
            
        Returns:
            list: ASINã®ãƒªã‚¹ãƒˆ
        """
        try:
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®è¨­å®š
            if input_file is None:
                input_file = self.config['keepa_api']['output']['input_file']
            elif not os.path.isabs(input_file):
                # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«ã™ã‚‹
                input_file = os.path.join(self.data_dir, input_file)
                
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            if not os.path.exists(input_file):
                error_msg = f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}"
                logger.error(error_msg)
                raise FileNotFoundError(error_msg)
                
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            df = pd.read_csv(input_file, encoding='utf-8-sig')
            
            # ASINåˆ—ã®å­˜åœ¨ç¢ºèª
            if asin_column not in df.columns:
                error_msg = f"'{asin_column}'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                logger.error(error_msg)
                raise ValueError(error_msg)
                
            # ASINãƒªã‚¹ãƒˆã®å–å¾—
            asins = df[asin_column].dropna().unique().tolist()
            logger.info(f"{len(asins)}ä»¶ã®ASINã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            print(f"ğŸ“ {len(asins)}ä»¶ã®ASINã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            print(f"ğŸ“„ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {input_file}")
            
            return asins
            
        except Exception as e:
            error_msg = f"ASINã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"
            logger.error(error_msg)
            raise
    
    @log_function_call
    def save_to_csv(self, df, output_file=None, encoding='utf-8-sig', append=False):
        """
        DataFrameã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹
        
        Args:
            df (pandas.DataFrame): ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            output_file (str, optional): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆçœç•¥æ™‚ã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä½¿ç”¨ï¼‰
            encoding (str): æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'utf-8-sig'ï¼‰
            append (bool): è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ã§ä¿å­˜ã™ã‚‹ã‹ã©ã†ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰
        """
        try:
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®è¨­å®š
            if output_file is None:
                output_file = self.config['keepa_api']['output']['output_file']
            elif not os.path.isabs(output_file):
                # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«ã™ã‚‹
                output_file = os.path.join(self.data_dir, output_file)
                
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            output_dir = os.path.dirname(output_file)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
                
            # CSVã¨ã—ã¦ä¿å­˜ï¼ˆè¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ã«å¯¾å¿œï¼‰
            mode = 'a' if append else 'w'
            header = not append or not os.path.exists(output_file)
            
            df.to_csv(output_file, index=False, encoding=encoding, mode=mode, header=header)
            
            action = "è¿½è¨˜" if append else "ä¿å­˜"
            logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚’{action}ã—ã¾ã—ãŸ: {output_file} ({len(df)}ä»¶)")
            print(f"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {output_file} ã«{action}ã—ã¾ã—ãŸ")
            
        except Exception as e:
            error_msg = f"ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"
            logger.error(error_msg)
            print(f"âŒ {error_msg}")
            raise


class ProductAnalyzerSingle(BaseKeepaAPISingle):
    """
    Keepa APIã‚’ä½¿ç”¨ã—ã¦å•†å“æƒ…å ±ã‚’1ASINãšã¤åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹
    
    ã“ã®ã‚¯ãƒ©ã‚¹ã¯ã€å•†å“æƒ…å ±ã®å–å¾—ãƒ»è§£æã«ç‰¹åŒ–ã—ãŸæ©Ÿèƒ½ã‚’1ASINãšã¤æä¾›ã—ã¾ã™ã€‚
    """
    
    def __init__(self, config_path=None):
        """
        ProductAnalyzerSingleã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        
        Args:
            config_path (str, optional): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰
        """
        # è¦ªã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        super().__init__(config_path)
        
        # å•†å“åˆ†æç”¨ã®è¨­å®š
        # ï¼ˆè¿½åŠ ã®è¨­å®šãŒå¿…è¦ãªå ´åˆã¯ã“ã“ã«è¨˜è¿°ï¼‰
    
    @log_function_call
    def _get_basic_info(self, product):
        """
        åŸºæœ¬çš„ãªå•†å“æƒ…å ±ã‚’å–å¾—
    
        Args:
            product (dict): å•†å“æƒ…å ±ã‚’å«ã‚€è¾æ›¸
    
        Returns:
            dict: åŸºæœ¬å•†å“æƒ…å ±ã‚’å«ã‚€è¾æ›¸
        """
        try:
            # ç”»åƒURLç”Ÿæˆ
            image_url = ("https://images-na.ssl-images-amazon.com/images/I/" + 
                        product.get('imagesCSV', '').split(',')[0]) if product.get('imagesCSV') else ''
    
            # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ASINã®å‡¦ç†ï¼ˆ5å€‹ã«åˆ¶é™ï¼‰
            variation_csv = product.get('variationCSV', '')
            if variation_csv:
                variations = variation_csv.split(',')[:5]  # æœ€åˆã®5å€‹ã‚’å–å¾—
                variation_limited = ','.join(variations)   # ã‚«ãƒ³ãƒã§çµåˆ
            else:
                variation_limited = ''
    
        except Exception as e:
            logger.warning(f"ç”»åƒURLç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            image_url = ''
            variation_limited = ''
    
        return {
            # åŸºæœ¬æƒ…å ±
            "ASIN": product.get('asin', ''),
            "JAN": self.safe_get(product, 'eanList', 0, default=''),
            "å•†å“å": product.get('title', ''),
            "ã‚«ãƒ†ã‚´ãƒªãƒ¼ID": product.get('rootCategory', ''),
            "ãƒ¡ãƒ¼ã‚«ãƒ¼å‹ç•ª": product.get('model', ''),
            "ãƒ¡ãƒ¼ã‚«ãƒ¼å": product.get('manufacturer', ''),
            "ãƒ–ãƒ©ãƒ³ãƒ‰å": product.get('brand', ''),
            "ã‚»ãƒƒãƒˆæ•°(Q)": product.get('packageQuantity', 0),
            "ã‚»ãƒƒãƒˆæ•°(N)": product.get('numberOfItems', 0),
            "ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ‰ç„¡": product.get('lastRatingUpdate', ''),
            "ã‚¢ãƒ€ãƒ«ãƒˆå•†å“å¯¾è±¡": product.get('isAdultProduct', False),
            "ç”»åƒURL": image_url,
            "ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ASIN": variation_limited,
    
            # URLæƒ…å ±
            "amazonURL": f"https://www.amazon.co.jp/dp/{product.get('asin', '')}",
            "KeepaURL": f"https://keepa.com/#!product/5-{product.get('asin', '')}"
        }
    
    @log_function_call
    def _safe_get_price(self, stats, index, sub_index=None):
        """
        ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å®‰å…¨ã«å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            stats (dict): çµ±è¨ˆæƒ…å ±ã‚’å«ã‚€è¾æ›¸
            index (str): å–å¾—ã—ãŸã„çµ±è¨ˆæƒ…å ±ã®ã‚­ãƒ¼ï¼ˆä¾‹: 'max', 'min', 'avg90'ï¼‰
            sub_index (int, optional): é…åˆ—å†…ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆAmazonä¾¡æ ¼ã¯0, æ–°å“ä¾¡æ ¼ã¯1ï¼‰
        
        Returns:
            int or None: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã€‚å–å¾—ã§ããªã„å ´åˆã¯None
        """
        try:
            if not stats or index not in stats:
                return None
                
            data = stats[index]
            if not data or not isinstance(data, list):
                return None
                
            # æœ€é«˜å€¤ãƒ»æœ€å®‰å€¤ã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†
            if index in ['max', 'min']:
                if len(data) <= sub_index or not data[sub_index]:
                    return None
                # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã¯[æ™‚åˆ», ä¾¡æ ¼]ã®å½¢å¼ã§æ ¼ç´ã•ã‚Œã¦ã„ã‚‹
                return data[sub_index][1] if len(data[sub_index]) > 1 else None
                
            # é€šå¸¸ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
            if sub_index is not None:
                if len(data) <= sub_index:
                    return None
                return data[sub_index]
                
            return data
        except Exception as e:
            logger.debug(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    @log_function_call
    def _get_price_info(self, product):
        """
        ä¾¡æ ¼é–¢é€£æƒ…å ±ã‚’å–å¾—ã™ã‚‹
        
        Args:
            product (dict): å•†å“æƒ…å ±ã‚’å«ã‚€è¾æ›¸
        
        Returns:
            dict: ä¾¡æ ¼é–¢é€£æƒ…å ±ã‚’å«ã‚€è¾æ›¸
        """
        # statsã®å–å¾—
        stats = product.get('stats', {})
        if not stats:
            logger.warning(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãªã— (ASIN: {product.get('asin', 'ä¸æ˜')})")
            return {}
            
        # ä¾¡æ ¼æƒ…å ±ã®å–å¾—
        price_info = {
            # Amazonä¾¡æ ¼å±¥æ­´
            "amazonä¾¡æ ¼_ç¾åœ¨ä¾¡æ ¼": self._safe_get_price(stats, 'current', 0),
            "amazonä¾¡æ ¼_æœ€é«˜ä¾¡æ ¼": self._safe_get_price(stats, 'max', 0),
            "amazonä¾¡æ ¼_æœ€ä½ä¾¡æ ¼": self._safe_get_price(stats, 'min', 0),
            "amazonä¾¡æ ¼_30æ—¥å¹³å‡ä¾¡æ ¼": self._safe_get_price(stats, 'avg30', 0),
            "amazonä¾¡æ ¼_90æ—¥å¹³å‡ä¾¡æ ¼": self._safe_get_price(stats, 'avg90', 0),
            "amazonä¾¡æ ¼_180æ—¥å¹³å‡ä¾¡æ ¼": self._safe_get_price(stats, 'avg180', 0),
    
            # æ–°å“ä¾¡æ ¼å±¥æ­´
            "æ–°å“ä¾¡æ ¼_ç¾åœ¨ä¾¡æ ¼": self._safe_get_price(stats, 'current', 1),
            "æ–°å“ä¾¡æ ¼_æœ€é«˜ä¾¡æ ¼": self._safe_get_price(stats, 'max', 1),
            "æ–°å“ä¾¡æ ¼_æœ€ä½ä¾¡æ ¼": self._safe_get_price(stats, 'min', 1),
            "æ–°å“ä¾¡æ ¼_30æ—¥å¹³å‡ä¾¡æ ¼": self._safe_get_price(stats, 'avg30', 1),
            "æ–°å“ä¾¡æ ¼_90æ—¥å¹³å‡ä¾¡æ ¼": self._safe_get_price(stats, 'avg90', 1),
            "æ–°å“ä¾¡æ ¼_180æ—¥å¹³å‡ä¾¡æ ¼": self._safe_get_price(stats, 'avg180', 1),
        }
        
        logger.debug(f"ä¾¡æ ¼æƒ…å ±ã®å–å¾—æˆåŠŸ: {product.get('asin', 'ä¸æ˜')}")
        return price_info

    @log_function_call
    def _get_rank_and_stock_info(self, product):
        """
        ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨åœ¨åº«æƒ…å ±ã‚’å–å¾—
        
        Args:
            product (dict): å•†å“æƒ…å ±ã‚’å«ã‚€è¾æ›¸
        
        Returns:
            dict: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨åœ¨åº«æƒ…å ±ã‚’å«ã‚€è¾æ›¸
        """
        stats = product.get('stats', {})
        
        return {
            "ç·å‡ºå“è€…æ•°": self.safe_get(product, 'stats', 'totalOfferCount', default=0),
            "30æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°": self.safe_get(product, 'stats', 'avg30', default=[0, 0, 0, 0])[3],
            "90æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°": self.safe_get(product, 'stats', 'avg90', default=[0, 0, 0, 0])[3],
            "180æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°": self.safe_get(product, 'stats', 'avg180', default=[0, 0, 0, 0])[3],
            "amazonæœ¬ä½“æœ‰ç„¡": product.get('availabilityAmazon', -1),
            "amazon_30æ—¥é–“åœ¨åº«åˆ‡ã‚Œç‡": self.safe_get(stats, 'outOfStockPercentage30', default=[0])[0] / 100,
            "amazon_90æ—¥é–“åœ¨åº«åˆ‡ã‚Œç‡": self.safe_get(stats, 'outOfStockPercentage90', default=[0])[0] / 100,
        }
    
    @log_function_call
    def parse_history(self, history):
        """
        å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
        
        Args:
            history (list): Keepa APIã‹ã‚‰å–å¾—ã—ãŸå±¥æ­´ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            dict: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚­ãƒ¼ã€å€¤ã‚’ãƒãƒªãƒ¥ãƒ¼ã¨ã™ã‚‹è¾æ›¸
        """
        if history is None:
            return {}  # Noneã®å ´åˆã¯ç©ºã®è¾æ›¸ã‚’è¿”ã™
        return {history[i]: history[i + 1] for i in range(0, len(history), 2)}

    @log_function_call
    def calculate_sales(self, product, days):
        """
        æŒ‡å®šæœŸé–“ã®è²©å£²æ•°ã‚’è¨ˆç®—
        
        Args:
            product (dict): å•†å“æƒ…å ±
            days (int): è¨ˆç®—å¯¾è±¡æœŸé–“ï¼ˆæ—¥æ•°ï¼‰
            
        Returns:
            tuple: (ç·è²©å£²æ•°, æ–°å“è²©å£²æ•°, ä¸­å¤è²©å£²æ•°, ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°)
        """
        try:
            # è²©å£²ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€å‡ºå“è€…æ•°ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            sales_rank_history = product['csv'][3]   # è²©å£²ãƒ©ãƒ³ã‚­ãƒ³ã‚°å±¥æ­´
            new_count_history = product['csv'][11]   # æ–°å“å‡ºå“è€…æ•°å±¥æ­´
            used_count_history = product['csv'][12]  # ä¸­å¤å‡ºå“è€…æ•°å±¥æ­´
            collectible_count_history = product['csv'][14]  # ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ å‡ºå“æ•°å±¥æ­´

            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
            sales_rank_dict = self.parse_history(sales_rank_history)
            used_count_dict = self.parse_history(used_count_history)
            collectible_count_dict = self.parse_history(collectible_count_history)

            if not sales_rank_dict:
                return 0, 0, 0, 0  # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯0ã‚’è¿”ã™

            # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–
            used_sales_count = 0
            collectible_sales_count = 0
            total_sales_count = 0

            # è¨ˆç®—ç¯„å›²ã®è¨­å®š
            latest_time = max(sales_rank_dict.keys())
            start_time = latest_time - (days * 24 * 60)  # daysæ—¥åˆ†ã®æ™‚é–“ï¼ˆåˆ†å˜ä½ï¼‰
            timestamps = sorted([t for t in sales_rank_dict.keys() if t >= start_time])

            # è²©å£²æ•°ã®è¨ˆç®—
            for i in range(1, len(timestamps)):
                t1, rank1 = timestamps[i - 1], sales_rank_dict[timestamps[i - 1]]
                t2, rank2 = timestamps[i], sales_rank_dict[timestamps[i]]

                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒä¸Šæ˜‡ï¼ˆæ•°å€¤ãŒæ¸›å°‘ï¼‰ã—ãŸå ´åˆ
                if rank1 * 1.00 > rank2:  # 0.1%ã§ã‚‚ä¸Šæ˜‡ã—ãŸã‚‰ã‚«ã‚¦ãƒ³ãƒˆ
                    total_sales_count += 1

                    # ä¸­å¤å•†å“ã®è²©å£²åˆ¤å®š
                    if used_count_dict:
                        used1 = used_count_dict.get(min(used_count_dict.keys(), key=lambda t: abs(t - t1)), 0)
                        used2 = used_count_dict.get(min(used_count_dict.keys(), key=lambda t: abs(t - t2)), 0)
                        if used1 > used2:
                            used_sales_count += 1

                    # ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ã®è²©å£²åˆ¤å®š
                    if collectible_count_dict:
                        coll1 = collectible_count_dict.get(min(collectible_count_dict.keys(), key=lambda t: abs(t - t1)), 0)
                        coll2 = collectible_count_dict.get(min(collectible_count_dict.keys(), key=lambda t: abs(t - t2)), 0)
                        if coll1 > coll2:
                            collectible_sales_count += 1

            # æ–°å“è²©å£²æ•°ã®è¨ˆç®—
            new_sales_count = total_sales_count - used_sales_count - collectible_sales_count
            
            return total_sales_count, new_sales_count, used_sales_count, collectible_sales_count

        except Exception as e:
            logger.error(f"è²©å£²æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return 0, 0, 0, 0

    @log_function_call
    def get_sales_data(self, product):
        """
        å•†å“ã®è²©å£²æ•°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            product (dict): å•†å“æƒ…å ±
            
        Returns:
            dict: è²©å£²æ•°æƒ…å ±ã‚’å«ã‚€è¾æ›¸
        """
        try:
            # 30æ—¥ã€90æ—¥ã€180æ—¥ã®è²©å£²æ•°ã‚’è¨ˆç®—
            sales_30 = self.calculate_sales(product, 30)
            sales_90 = self.calculate_sales(product, 90)
            sales_180 = self.calculate_sales(product, 180)

            # Keepa APIã®çµ±è¨ˆæƒ…å ±ã‚‚å–å¾—ï¼ˆæ¯”è¼ƒç”¨ï¼‰
            stats = product.get('stats', {})
            
            return {
                # 30æ—¥ãƒ‡ãƒ¼ã‚¿
                "30æ—¥é–“_ç·è²©å£²æ•°": sales_30[0],
                "30æ—¥é–“_æ–°å“è²©å£²æ•°": sales_30[1],
                "30æ—¥é–“_ä¸­å¤è²©å£²æ•°": sales_30[2],
                "30æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°": sales_30[3],
                "Keepa30æ—¥é–“è²©å£²æ•°": stats.get('salesRankDrops30', 0),

                # 90æ—¥ãƒ‡ãƒ¼ã‚¿
                "90æ—¥é–“_ç·è²©å£²æ•°": sales_90[0],
                "90æ—¥é–“_æ–°å“è²©å£²æ•°": sales_90[1],
                "90æ—¥é–“_ä¸­å¤è²©å£²æ•°": sales_90[2],
                "90æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°": sales_90[3],
                "Keepa90æ—¥é–“è²©å£²æ•°": stats.get('salesRankDrops90', 0),

                # 180æ—¥ãƒ‡ãƒ¼ã‚¿
                "180æ—¥é–“_ç·è²©å£²æ•°": sales_180[0],
                "180æ—¥é–“_æ–°å“è²©å£²æ•°": sales_180[1],
                "180æ—¥é–“_ä¸­å¤è²©å£²æ•°": sales_180[2],
                "180æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°": sales_180[3],
                "Keepa180æ—¥é–“è²©å£²æ•°": stats.get('salesRankDrops180', 0)
            }

        except Exception as e:
            logger.error(f"è²©å£²ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}
    
    @log_function_call
    def get_single_product_data(self, asin):
        """
        å˜ä¸€ASINã®å•†å“æƒ…å ±ã‚’å–å¾—ã™ã‚‹
        
        Args:
            asin (str): å˜ä¸€ã®ASIN
            
        Returns:
            pandas.DataFrame: å•†å“æƒ…å ±ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆ1è¡Œã®ã¿ï¼‰
                              ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        logger.info(f"å•†å“æƒ…å ±ã®å–å¾—ã‚’é–‹å§‹: {asin}")
        
        # 1. å˜ä¸€ASINã«å¯¾ã™ã‚‹APIå‘¼ã³å‡ºã—
        products = self._call_api_single(asin)
        if products is None or len(products) == 0:
            logger.warning(f"å•†å“æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {asin}")
            return pd.DataFrame()
        
        # 2. å˜ä¸€å•†å“ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        product_data = []
        try:
            # ãƒªã‚¹ãƒˆã‹ã‚‰å¯¾è±¡å•†å“ã‚’å–å¾—ï¼ˆé€šå¸¸ã¯1ä»¶ã®ã¿ï¼‰
            product = products[0]
            
            # åŸºæœ¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            if not product.get('stats'):
                logger.warning(f"å•†å“ãƒ‡ãƒ¼ã‚¿ãªã— (ASIN: {asin})")
                return pd.DataFrame()

            # å•†å“æƒ…å ±ã®å–å¾—ã¨çµ±åˆ
            product_info = self._get_basic_info(product)
            price_info = self._get_price_info(product)
            rank_stock_info = self._get_rank_and_stock_info(product)
            sales_info = self.get_sales_data(product)
            
            # å…¨ã¦ã®æƒ…å ±ã‚’çµ±åˆ
            product_info.update(price_info)
            product_info.update(rank_stock_info)
            product_info.update(sales_info)
            
            # æ—¥ä»˜æƒ…å ±ã®è¿½åŠ 
            product_info["å•†å“è¿½è·¡æ—¥"] = product.get('trackingSince', '')
            product_info["å•†å“ç™ºå£²æ—¥"] = None if product.get('releaseDate', -1) == -1 else product['releaseDate']
            
            tracking_since = product.get('trackingSince')
            if tracking_since:
                try:
                    unix_timestamp = (tracking_since + 21564000) * 60
                    tracking_date = datetime.fromtimestamp(unix_timestamp)
                    product_info["è¿½è·¡é–‹å§‹ã‹ã‚‰ã®çµŒéæ—¥æ•°"] = (datetime.today() - tracking_date).days
                except Exception as e:
                    logger.warning(f"çµŒéæ—¥æ•°ã®è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    product_info["è¿½è·¡é–‹å§‹ã‹ã‚‰ã®çµŒéæ—¥æ•°"] = None
            else:
                product_info["è¿½è·¡é–‹å§‹ã‹ã‚‰ã®çµŒéæ—¥æ•°"] = None
            
            product_data.append(product_info)
            logger.debug(f"å•†å“ãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ: {asin}")
            
        except Exception as e:
            logger.error(f"å•†å“ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ (ASIN: {asin}): {str(e)}")
            return pd.DataFrame()

        # å¸Œæœ›ã™ã‚‹åˆ—ã®é †åºã‚’å®šç¾©
        desired_columns = [
            # åŸºæœ¬æƒ…å ±
            "ASIN", "JAN", "å•†å“å", "ã‚«ãƒ†ã‚´ãƒªãƒ¼ID", "ãƒ¡ãƒ¼ã‚«ãƒ¼å‹ç•ª", "ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ‰ç„¡", 
            "ãƒ¡ãƒ¼ã‚«ãƒ¼å", "ãƒ–ãƒ©ãƒ³ãƒ‰å", "ç·å‡ºå“è€…æ•°", "ã‚»ãƒƒãƒˆæ•°(Q)", "ã‚»ãƒƒãƒˆæ•°(N)", "å•†å“è¿½è·¡æ—¥", 
            "å•†å“ç™ºå£²æ—¥", "è¿½è·¡é–‹å§‹ã‹ã‚‰ã®çµŒéæ—¥æ•°", "ã‚¢ãƒ€ãƒ«ãƒˆå•†å“å¯¾è±¡", "ç”»åƒURL",
            
            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»URLæƒ…å ±
            "30æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "90æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "180æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°",
            "amazonURL", "KeepaURL", "ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ASIN",
            
            # Amazonãƒ»åœ¨åº«æƒ…å ±
            "amazonæœ¬ä½“æœ‰ç„¡", "amazon_30æ—¥é–“åœ¨åº«åˆ‡ã‚Œç‡", "amazon_90æ—¥é–“åœ¨åº«åˆ‡ã‚Œç‡",
            
            # ä¾¡æ ¼æƒ…å ±
            "amazonä¾¡æ ¼_ç¾åœ¨ä¾¡æ ¼", "amazonä¾¡æ ¼_æœ€é«˜ä¾¡æ ¼", "amazonä¾¡æ ¼_æœ€ä½ä¾¡æ ¼",
            "amazonä¾¡æ ¼_30æ—¥å¹³å‡ä¾¡æ ¼", "amazonä¾¡æ ¼_90æ—¥å¹³å‡ä¾¡æ ¼", "amazonä¾¡æ ¼_180æ—¥å¹³å‡ä¾¡æ ¼",
            "æ–°å“ä¾¡æ ¼_ç¾åœ¨ä¾¡æ ¼", "æ–°å“ä¾¡æ ¼_æœ€é«˜ä¾¡æ ¼", "æ–°å“ä¾¡æ ¼_æœ€ä½ä¾¡æ ¼",
            "æ–°å“ä¾¡æ ¼_30æ—¥å¹³å‡ä¾¡æ ¼", "æ–°å“ä¾¡æ ¼_90æ—¥å¹³å‡ä¾¡æ ¼", "æ–°å“ä¾¡æ ¼_180æ—¥å¹³å‡ä¾¡æ ¼",
            
            # è²©å£²æ•°æƒ…å ±
            "30æ—¥é–“_ç·è²©å£²æ•°", "30æ—¥é–“_æ–°å“è²©å£²æ•°", "30æ—¥é–“_ä¸­å¤è²©å£²æ•°", "30æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°", "Keepa30æ—¥é–“è²©å£²æ•°",
            "90æ—¥é–“_ç·è²©å£²æ•°", "90æ—¥é–“_æ–°å“è²©å£²æ•°", "90æ—¥é–“_ä¸­å¤è²©å£²æ•°", "90æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°", "Keepa90æ—¥é–“è²©",
            "90æ—¥é–“_ç·è²©å£²æ•°", "90æ—¥é–“_æ–°å“è²©å£²æ•°", "90æ—¥é–“_ä¸­å¤è²©å£²æ•°", "90æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°", "Keepa90æ—¥é–“è²©å£²æ•°",
            "180æ—¥é–“_ç·è²©å£²æ•°", "180æ—¥é–“_æ–°å“è²©å£²æ•°", "180æ—¥é–“_ä¸­å¤è²©å£²æ•°", "180æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°", "Keepa180æ—¥é–“è²©å£²æ•°"
        ]
        
        # DataFrameã®åˆ—ã‚’æŒ‡å®šã—ãŸé †åºã«ä¸¦ã³æ›¿ãˆ
        df = pd.DataFrame(product_data)
        
        # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’æŠ½å‡ºï¼ˆã‚¨ãƒ©ãƒ¼é˜²æ­¢ã®ãŸã‚ï¼‰
        valid_columns = [col for col in desired_columns if col in df.columns]
        df = df[valid_columns]
        
        logger.info(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: ASIN {asin}")
        return df

    @log_function_call
    def process_multiple_asins(self, asin_list, output_file=None, interval=1.0):
        """
        è¤‡æ•°ã®ASINã‚’1ã¤ãšã¤é †ç•ªã«å‡¦ç†ã—ã€çµæœã‚’1ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹
        
        Args:
            asin_list (list): å‡¦ç†ã™ã‚‹ASINã®ãƒªã‚¹ãƒˆ
            output_file (str, optional): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            interval (float): ASINã”ã¨ã®å‡¦ç†é–“éš”ï¼ˆç§’ï¼‰
            
        Returns:
            int: å‡¦ç†ã«æˆåŠŸã—ãŸASINã®æ•°
        """
        # å®Ÿè¡Œæ™‚é–“ã®è¨ˆæ¸¬é–‹å§‹
        start_time = time.time()
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™
        if output_file is None:
            output_file = self.config['keepa_api']['output']['output_file']
        
        # æˆåŠŸä»¶æ•°ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        success_count = 0
        
        # æœ€åˆã®ASINã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆæœŸåŒ–ç”¨ã«ä½¿ç”¨
        first_time = True
        
        try:
            # å„ASINã‚’1ã¤ãšã¤å‡¦ç†
            for i, asin in enumerate(asin_list, 1):
                logger.info(f"å‡¦ç†ä¸­ ({i}/{len(asin_list)}): ASIN {asin}")
                print(f"ğŸ” å‡¦ç†ä¸­ ({i}/{len(asin_list)}): ASIN {asin}")
                
                # å˜ä¸€ASINå‡¦ç†
                df = self.get_single_product_data(asin)
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã§ãªã‘ã‚Œã°ä¿å­˜
                if not df.empty:
                    # æœ€åˆã®ASINã®å ´åˆã¯æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã€ä»¥é™ã¯è¿½è¨˜
                    append_mode = not first_time
                    self.save_to_csv(df, output_file=output_file, append=append_mode)
                    first_time = False
                    success_count += 1
                
                # å‡¦ç†é–“éš”ã®å¾…æ©Ÿï¼ˆæœ€å¾Œã®ASINä»¥å¤–ï¼‰
                if i < len(asin_list):
                    time.sleep(interval)
                    
            # å®Ÿè¡Œæ™‚é–“ã®è¨ˆæ¸¬çµ‚äº†
            end_time = time.time()
            elapsed_time = end_time - start_time
            
            # çµæœã®å‡ºåŠ›
            logger.info(f"å‡¦ç†å®Œäº†: {success_count}/{len(asin_list)}ä»¶ã®ASINã‚’å‡¦ç†ã—ã¾ã—ãŸ")
            print(f"\nâœ… å‡¦ç†å®Œäº†: {success_count}/{len(asin_list)}ä»¶ã®ASINã‚’å‡¦ç†ã—ã¾ã—ãŸ")
            print(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f}ç§’ (å¹³å‡: {elapsed_time/len(asin_list):.2f}ç§’/ASIN)")
            
            return success_count
            
        except Exception as e:
            logger.error(f"è¤‡æ•°ASINå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            traceback.print_exc()
            return success_count