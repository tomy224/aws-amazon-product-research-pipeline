{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–‹ç™ºéç¨‹ã®è£œè¶³\n",
    "\n",
    "# ã“ã® Jupyter Notebook ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€é–‹ç™ºéç¨‹ã‚’ç¤ºã™ãŸã‚ã«ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚  \n",
    "# ã‚»ãƒ«å˜ä½ã§ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ãªãŒã‚‰å‡¦ç†å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã€Œæ¤œè¨¼ç”¨ç’°å¢ƒã€ã¨ã—ã¦ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚  \n",
    "# å®Ÿéš›ã®æœ¬ç•ªç’°å¢ƒã§ã¯ VSCode ä¸Šã§ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã€AWS Lambda ãŠã‚ˆã³ Step Functions ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739aeb42-95ec-4549-813e-b88c5ed6b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–‹ç™ºå±¥æ­´å‚ç…§ã®ãŸã‚æ®‹ã—ã¦ãŠãã€‚\n",
    "\n",
    "# ã‚»ãƒ«1: å…±é€šæ©Ÿèƒ½ - ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
    "import keepa\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import dotenv\n",
    "import traceback\n",
    "\n",
    "# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆæ¤œå‡º\n",
    "def find_project_root():\n",
    "    \"\"\"\n",
    "    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œå‡ºã™ã‚‹\n",
    "    \"\"\"\n",
    "    # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’å–å¾—\n",
    "    current_dir = os.path.abspath(os.getcwd())\n",
    "    \n",
    "    # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢\n",
    "    path = Path(current_dir)\n",
    "    while True:\n",
    "        # .gitãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Œã°ãã‚Œã‚’ãƒ«ãƒ¼ãƒˆã¨ã¿ãªã™\n",
    "        if (path / '.git').exists():\n",
    "            return str(path)\n",
    "        \n",
    "        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆã‚’ç¤ºã™ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯\n",
    "        if (path / 'setup.py').exists() or (path / 'README.md').exists():\n",
    "            return str(path)\n",
    "        \n",
    "        # ã“ã‚Œä»¥ä¸Šä¸Šã®éšå±¤ãŒãªã„å ´åˆã¯ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿”ã™\n",
    "        if path.parent == path:\n",
    "            return str(path)\n",
    "        \n",
    "        # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸\n",
    "        path = path.parent\n",
    "\n",
    "# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° - è¨­å®šèª­ã¿è¾¼ã¿\n",
    "def load_config(root_dir, config_path=None):\n",
    "    \"\"\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\"\"\"\n",
    "    if config_path is None:\n",
    "        config_path = os.path.join(root_dir, 'config', 'settings.yaml')\n",
    "        \n",
    "    try:\n",
    "        with open(config_path, 'r', encoding='utf-8') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "            \n",
    "        # Keepa APIè¨­å®šã®å­˜åœ¨ç¢ºèª\n",
    "        if 'keepa_api' not in config:\n",
    "            raise ValueError(\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«keepa_apiã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            \n",
    "        # å‡ºåŠ›è¨­å®šã®åˆæœŸåŒ–ï¼ˆãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼‰\n",
    "        data_dir = os.path.join(root_dir, 'data')\n",
    "        if 'output' not in config['keepa_api']:\n",
    "            config['keepa_api']['output'] = {\n",
    "                'input_file': os.path.join(data_dir, 'sp_api_output_filtered.csv'),\n",
    "                'output_file': os.path.join(data_dir, 'keepa_output.csv')\n",
    "            }\n",
    "        else:\n",
    "            # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›\n",
    "            for key in ['input_file', 'output_file']:\n",
    "                if key in config['keepa_api']['output']:\n",
    "                    rel_path = config['keepa_api']['output'][key]\n",
    "                    if not os.path.isabs(rel_path):\n",
    "                        config['keepa_api']['output'][key] = os.path.join(data_dir, rel_path)\n",
    "                \n",
    "        logging.info(f\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸ: {config_path}\")\n",
    "        return config\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° - ãƒ­ã‚°è¨­å®š\n",
    "def setup_logging(log_dir, name_prefix=\"keepa_product\"):\n",
    "    \"\"\"ãƒ­ã‚°æ©Ÿèƒ½ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\"\"\"\n",
    "    # ã™ã§ã«å­˜åœ¨ã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©ã‚’å‰Šé™¤ï¼ˆé‡è¤‡ã‚’é˜²ããŸã‚ï¼‰\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    \n",
    "    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š\n",
    "    log_file = os.path.join(log_dir, f'{name_prefix}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "    \n",
    "    # åŸºæœ¬è¨­å®š\n",
    "    logging.basicConfig(\n",
    "        filename=log_file,\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚ãƒ­ã‚°ã‚’å‡ºåŠ›\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console.setFormatter(formatter)\n",
    "    logging.getLogger('').addHandler(console)\n",
    "    \n",
    "    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€ã‚’æ˜ç¤ºçš„ã«è¡¨ç¤º\n",
    "    print(f\"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {log_file}\")\n",
    "    logging.info(f\"ãƒ­ã‚°æ©Ÿèƒ½ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ: {log_file}\")\n",
    "    \n",
    "    return log_file\n",
    "\n",
    "# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° - å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "def safe_get(data, *keys, default=None):\n",
    "    \"\"\"åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å–å¾—ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\"\"\"\n",
    "    for key in keys:\n",
    "        try:\n",
    "            data = data[key]\n",
    "        except (KeyError, TypeError, IndexError):\n",
    "            return default\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b413dc-894d-45c9-90c9-b12408a8a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«2: KeepaProductAnalyzerã‚¯ãƒ©ã‚¹ã®å®šç¾© - åˆæœŸåŒ–ã¨åŸºæœ¬æƒ…å ±å–å¾—\n",
    "class KeepaProductAnalyzer:\n",
    "    \"\"\"Keepa APIã‚’ä½¿ç”¨ã—ã¦å•†å“æƒ…å ±ã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path=None):\n",
    "        \"\"\"\n",
    "        åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        config_path : str, optional\n",
    "            è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚æŒ‡å®šãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ä½¿ç”¨\n",
    "        \"\"\"\n",
    "        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œå‡º\n",
    "        self.root_dir = find_project_root()\n",
    "        \n",
    "        # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "        dotenv.load_dotenv(os.path.join(self.root_dir, '.env'))\n",
    "        \n",
    "        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®è¨­å®š\n",
    "        self.data_dir = os.path.join(self.root_dir, 'data')\n",
    "        self.log_dir = os.path.join(self.root_dir, 'logs')\n",
    "        \n",
    "        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
    "        os.makedirs(self.data_dir, exist_ok=True)\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "        \n",
    "        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "        self.config = load_config(self.root_dir, config_path)\n",
    "        \n",
    "        # ãƒ­ã‚°æ©Ÿèƒ½ã®åˆæœŸåŒ–\n",
    "        self.log_file = setup_logging(self.log_dir)\n",
    "        \n",
    "        try:\n",
    "            # Keepa APIã®åˆæœŸåŒ–ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ãŸAPIã‚­ãƒ¼ã‚’ä½¿ç”¨ï¼‰\n",
    "            api_key = os.getenv('KEEPA_API_KEY') or self.config['keepa_api'].get('api_key')\n",
    "            self.api = keepa.Keepa(api_key)\n",
    "            logging.info(\"Keepa APIã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸ\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Keepa APIã®åˆæœŸåŒ–ã«å¤±æ•—: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _call_api(self, asin_list):\n",
    "        \"\"\"\n",
    "        Keepa APIã‚’å‘¼ã³å‡ºã™\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        asin_list : list\n",
    "            ASINã®ãƒªã‚¹ãƒˆ\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        list or None\n",
    "            Keepa APIã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            products = self.api.query(\n",
    "                asin_list,\n",
    "                domain=self.config['keepa_api'].get('domain', 5),  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ—¥æœ¬ï¼ˆ5ï¼‰\n",
    "                stats=self.config['keepa_api'].get('stats_days', 180),  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯180æ—¥\n",
    "                days=self.config['keepa_api'].get('stats_days', 180),\n",
    "                update=1\n",
    "            )\n",
    "            logging.info(f\"APIå‘¼ã³å‡ºã—æˆåŠŸ: {len(products)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\")\n",
    "            return products\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _get_basic_info(self, product):\n",
    "        \"\"\"\n",
    "        åŸºæœ¬çš„ãªå•†å“æƒ…å ±ã‚’å–å¾—\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        product : dict\n",
    "            å•†å“æƒ…å ±ã‚’å«ã‚€è¾æ›¸\n",
    "    \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            åŸºæœ¬å•†å“æƒ…å ±ã‚’å«ã‚€è¾æ›¸\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ç”»åƒURLç”Ÿæˆ\n",
    "            image_url = (\"https://images-na.ssl-images-amazon.com/images/I/\" + \n",
    "                        product.get('imagesCSV', '').split(',')[0]) if product.get('imagesCSV') else ''\n",
    "    \n",
    "            # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ASINã®å‡¦ç†ï¼ˆ5å€‹ã«åˆ¶é™ï¼‰\n",
    "            variation_csv = product.get('variationCSV', '')\n",
    "            if variation_csv:\n",
    "                variations = variation_csv.split(',')[:5]  # æœ€åˆã®5å€‹ã‚’å–å¾—\n",
    "                variation_limited = ','.join(variations)   # ã‚«ãƒ³ãƒã§çµåˆ\n",
    "            else:\n",
    "                variation_limited = ''\n",
    "    \n",
    "            # # ã‚«ãƒ†ã‚´ãƒªå–å¾—ï¼ˆcategoryTreeã®2ã¤ç›®ã®nameã‚’å–å¾—ï¼‰\n",
    "            # category_name = product.get('categoryTree', [{}])[1].get('name', '') if len(product.get('categoryTree', [])) > 1 else ''\n",
    "    \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"ç”»åƒURLç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            image_url = ''\n",
    "            variation_limited = ''\n",
    "            category_name = ''\n",
    "    \n",
    "        return {\n",
    "            # åŸºæœ¬æƒ…å ±\n",
    "            \"ASIN\": product.get('asin', ''),\n",
    "            \"JAN\": safe_get(product, 'eanList', 0, default=''),\n",
    "            \"å•†å“å\": product.get('title', ''),\n",
    "            \"ã‚«ãƒ†ã‚´ãƒªãƒ¼\": product.get('rootCategory', ''),\n",
    "            \"ãƒ¡ãƒ¼ã‚«ãƒ¼å‹ç•ª\": product.get('model', ''),\n",
    "            \"ãƒ¡ãƒ¼ã‚«ãƒ¼å\": product.get('manufacturer', ''),\n",
    "            \"ãƒ–ãƒ©ãƒ³ãƒ‰å\": product.get('brand', ''),\n",
    "            \"ã‚»ãƒƒãƒˆæ•°(Q)\": product.get('packageQuantity', 0),\n",
    "            \"ã‚»ãƒƒãƒˆæ•°(N)\": product.get('numberOfItems', 0),\n",
    "            \"ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ‰ç„¡\": product.get('lastRatingUpdate', ''),\n",
    "            \"ã‚¢ãƒ€ãƒ«ãƒˆå•†å“å¯¾è±¡\": product.get('isAdultProduct', False),\n",
    "            \"ç”»åƒURL\": image_url,\n",
    "            \"ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ASIN\": variation_limited,\n",
    "    \n",
    "            # URLæƒ…å ±\n",
    "            \"amazonURL\": f\"https://www.amazon.co.jp/dp/{product.get('asin', '')}\",\n",
    "            \"KeepaURL\": f\"https://keepa.com/#!product/5-{product.get('asin', '')}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5377ecb-9d26-43a2-a685-5c5aa24b2da4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«3: ä¾¡æ ¼æƒ…å ±ã¨çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "class KeepaProductAnalyzer(KeepaProductAnalyzer):  \n",
    "    def _safe_get_price(self, stats, index, sub_index=None):\n",
    "        \"\"\"\n",
    "        ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å®‰å…¨ã«å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        stats : dict\n",
    "            çµ±è¨ˆæƒ…å ±ã‚’å«ã‚€è¾æ›¸\n",
    "        index : str\n",
    "            å–å¾—ã—ãŸã„çµ±è¨ˆæƒ…å ±ã®ã‚­ãƒ¼ï¼ˆä¾‹: 'max', 'min', 'avg90'ï¼‰\n",
    "        sub_index : int, optional\n",
    "            é…åˆ—å†…ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆAmazonä¾¡æ ¼ã¯0, æ–°å“ä¾¡æ ¼ã¯1ï¼‰\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        int or None\n",
    "            ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã€‚å–å¾—ã§ããªã„å ´åˆã¯None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not stats or index not in stats:\n",
    "                return None\n",
    "                \n",
    "            data = stats[index]\n",
    "            if not data or not isinstance(data, list):\n",
    "                return None\n",
    "                \n",
    "            # æœ€é«˜å€¤ãƒ»æœ€å®‰å€¤ã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†\n",
    "            if index in ['max', 'min']:\n",
    "                if len(data) <= sub_index or not data[sub_index]:\n",
    "                    return None\n",
    "                # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã¯[æ™‚åˆ», ä¾¡æ ¼]ã®å½¢å¼ã§æ ¼ç´ã•ã‚Œã¦ã„ã‚‹\n",
    "                return data[sub_index][1] if len(data[sub_index]) > 1 else None\n",
    "                \n",
    "            # é€šå¸¸ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ\n",
    "            if sub_index is not None:\n",
    "                if len(data) <= sub_index:\n",
    "                    return None\n",
    "                return data[sub_index]\n",
    "                \n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logging.debug(f\"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _get_price_info(self, product):\n",
    "        \"\"\"\n",
    "        ä¾¡æ ¼é–¢é€£æƒ…å ±ã‚’å–å¾—ã™ã‚‹\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        product : dict\n",
    "            å•†å“æƒ…å ±ã‚’å«ã‚€è¾æ›¸\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            ä¾¡æ ¼é–¢é€£æƒ…å ±ã‚’å«ã‚€è¾æ›¸\n",
    "        \"\"\"\n",
    "        # statsã®å–å¾—\n",
    "        stats = product.get('stats', {})\n",
    "        if not stats:\n",
    "            logging.warning(f\"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãªã— (ASIN: {product.get('asin', 'ä¸æ˜')})\")\n",
    "            return {}\n",
    "            \n",
    "        # ä¾¡æ ¼æƒ…å ±ã®å–å¾—\n",
    "        price_info = {\n",
    "            # Amazonä¾¡æ ¼å±¥æ­´\n",
    "            \"amazonä¾¡æ ¼_ç¾åœ¨ä¾¡æ ¼\": self._safe_get_price(stats, 'current', 0),\n",
    "            \"amazonä¾¡æ ¼_æœ€é«˜ä¾¡æ ¼\": self._safe_get_price(stats, 'max', 0),\n",
    "            \"amazonä¾¡æ ¼_æœ€ä½ä¾¡æ ¼\": self._safe_get_price(stats, 'min', 0),\n",
    "            \"amazonä¾¡æ ¼_30æ—¥å¹³å‡ä¾¡æ ¼\": self._safe_get_price(stats, 'avg30', 0),\n",
    "            \"amazonä¾¡æ ¼_90æ—¥å¹³å‡ä¾¡æ ¼\": self._safe_get_price(stats, 'avg90', 0),\n",
    "            \"amazonä¾¡æ ¼_180æ—¥å¹³å‡ä¾¡æ ¼\": self._safe_get_price(stats, 'avg180', 0),\n",
    "    \n",
    "            # æ–°å“ä¾¡æ ¼å±¥æ­´\n",
    "            \"æ–°å“ä¾¡æ ¼_ç¾åœ¨ä¾¡æ ¼\": self._safe_get_price(stats, 'current', 1),\n",
    "            \"æ–°å“ä¾¡æ ¼_æœ€é«˜ä¾¡æ ¼\": self._safe_get_price(stats, 'max', 1),\n",
    "            \"æ–°å“ä¾¡æ ¼_æœ€ä½ä¾¡æ ¼\": self._safe_get_price(stats, 'min', 1),\n",
    "            \"æ–°å“ä¾¡æ ¼_30æ—¥å¹³å‡ä¾¡æ ¼\": self._safe_get_price(stats, 'avg30', 1),\n",
    "            \"æ–°å“ä¾¡æ ¼_90æ—¥å¹³å‡ä¾¡æ ¼\": self._safe_get_price(stats, 'avg90', 1),\n",
    "            \"æ–°å“ä¾¡æ ¼_180æ—¥å¹³å‡ä¾¡æ ¼\": self._safe_get_price(stats, 'avg180', 1),\n",
    "        }\n",
    "        \n",
    "        logging.debug(f\"ä¾¡æ ¼æƒ…å ±ã®å–å¾—æˆåŠŸ: {product.get('asin', 'ä¸æ˜')}\")\n",
    "        return price_info\n",
    "\n",
    "    def _get_rank_and_stock_info(self, product):\n",
    "        \"\"\"\n",
    "        ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨åœ¨åº«æƒ…å ±ã‚’å–å¾—\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        product : dict\n",
    "            å•†å“æƒ…å ±ã‚’å«ã‚€è¾æ›¸\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨åœ¨åº«æƒ…å ±ã‚’å«ã‚€è¾æ›¸\n",
    "        \"\"\"\n",
    "        stats = product.get('stats', {})\n",
    "        \n",
    "        return {\n",
    "            \"ç·å‡ºå“è€…æ•°\": safe_get(product, 'stats', 'totalOfferCount', default=0),\n",
    "            \"30æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°\": safe_get(product, 'stats', 'avg30', default=[0, 0, 0, 0])[3],\n",
    "            \"90æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°\": safe_get(product, 'stats', 'avg90', default=[0, 0, 0, 0])[3],\n",
    "            \"180æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°\": safe_get(product, 'stats', 'avg180', default=[0, 0, 0, 0])[3],\n",
    "            \"amazonæœ¬ä½“æœ‰ç„¡\": product.get('availabilityAmazon', -1),\n",
    "            \"amazon_30æ—¥é–“åœ¨åº«åˆ‡ã‚Œç‡\": safe_get(stats, 'outOfStockPercentage30', default=[0])[0],\n",
    "            \"amazon_90æ—¥é–“åœ¨åº«åˆ‡ã‚Œç‡\": safe_get(stats, 'outOfStockPercentage90', default=[0])[0],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad605c-d633-4cb8-98a6-b8ebdd5c8d13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«4: è²©å£²æ•°è¨ˆç®—ã¨å±¥æ­´ãƒ‡ãƒ¼ã‚¿å‡¦ç†\n",
    "class KeepaProductAnalyzer(KeepaProductAnalyzer):\n",
    "    def parse_history(self, history):\n",
    "        \"\"\"\n",
    "        å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        history : list\n",
    "            Keepa APIã‹ã‚‰å–å¾—ã—ãŸå±¥æ­´ãƒ‡ãƒ¼ã‚¿\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚­ãƒ¼ã€å€¤ã‚’ãƒãƒªãƒ¥ãƒ¼ã¨ã™ã‚‹è¾æ›¸\n",
    "        \"\"\"\n",
    "        if history is None:\n",
    "            return {}  # Noneã®å ´åˆã¯ç©ºã®è¾æ›¸ã‚’è¿”ã™\n",
    "        return {history[i]: history[i + 1] for i in range(0, len(history), 2)}\n",
    "\n",
    "    def calculate_sales(self, product, days):\n",
    "        \"\"\"\n",
    "        æŒ‡å®šæœŸé–“ã®è²©å£²æ•°ã‚’è¨ˆç®—\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        product : dict\n",
    "            å•†å“æƒ…å ±\n",
    "        days : int\n",
    "            è¨ˆç®—å¯¾è±¡æœŸé–“ï¼ˆæ—¥æ•°ï¼‰\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            (ç·è²©å£²æ•°, æ–°å“è²©å£²æ•°, ä¸­å¤è²©å£²æ•°, ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # è²©å£²ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€å‡ºå“è€…æ•°ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "            sales_rank_history = product['csv'][3]   # è²©å£²ãƒ©ãƒ³ã‚­ãƒ³ã‚°å±¥æ­´\n",
    "            new_count_history = product['csv'][11]   # æ–°å“å‡ºå“è€…æ•°å±¥æ­´\n",
    "            used_count_history = product['csv'][12]  # ä¸­å¤å‡ºå“è€…æ•°å±¥æ­´\n",
    "            collectible_count_history = product['csv'][14]  # ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ å‡ºå“æ•°å±¥æ­´\n",
    "\n",
    "            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›\n",
    "            sales_rank_dict = self.parse_history(sales_rank_history)\n",
    "            used_count_dict = self.parse_history(used_count_history)\n",
    "            collectible_count_dict = self.parse_history(collectible_count_history)\n",
    "\n",
    "            if not sales_rank_dict:\n",
    "                return 0, 0, 0, 0  # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯0ã‚’è¿”ã™\n",
    "\n",
    "            # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–\n",
    "            used_sales_count = 0\n",
    "            collectible_sales_count = 0\n",
    "            total_sales_count = 0\n",
    "\n",
    "            # è¨ˆç®—ç¯„å›²ã®è¨­å®š\n",
    "            latest_time = max(sales_rank_dict.keys())\n",
    "            start_time = latest_time - (days * 24 * 60)  # daysæ—¥åˆ†ã®æ™‚é–“ï¼ˆåˆ†å˜ä½ï¼‰\n",
    "            timestamps = sorted([t for t in sales_rank_dict.keys() if t >= start_time])\n",
    "\n",
    "            # è²©å£²æ•°ã®è¨ˆç®—\n",
    "            for i in range(1, len(timestamps)):\n",
    "                t1, rank1 = timestamps[i - 1], sales_rank_dict[timestamps[i - 1]]\n",
    "                t2, rank2 = timestamps[i], sales_rank_dict[timestamps[i]]\n",
    "\n",
    "                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒä¸Šæ˜‡ï¼ˆæ•°å€¤ãŒæ¸›å°‘ï¼‰ã—ãŸå ´åˆ\n",
    "                if rank1 * 1.00 > rank2:  # 0.1%ã§ã‚‚ä¸Šæ˜‡ã—ãŸã‚‰ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "                    total_sales_count += 1\n",
    "\n",
    "                    # ä¸­å¤å•†å“ã®è²©å£²åˆ¤å®š\n",
    "                    if used_count_dict:\n",
    "                        used1 = used_count_dict.get(min(used_count_dict.keys(), key=lambda t: abs(t - t1)), 0)\n",
    "                        used2 = used_count_dict.get(min(used_count_dict.keys(), key=lambda t: abs(t - t2)), 0)\n",
    "                        if used1 > used2:\n",
    "                            used_sales_count += 1\n",
    "\n",
    "                    # ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ã®è²©å£²åˆ¤å®š\n",
    "                    if collectible_count_dict:\n",
    "                        coll1 = collectible_count_dict.get(min(collectible_count_dict.keys(), key=lambda t: abs(t - t1)), 0)\n",
    "                        coll2 = collectible_count_dict.get(min(collectible_count_dict.keys(), key=lambda t: abs(t - t2)), 0)\n",
    "                        if coll1 > coll2:\n",
    "                            collectible_sales_count += 1\n",
    "\n",
    "            # æ–°å“è²©å£²æ•°ã®è¨ˆç®—\n",
    "            new_sales_count = total_sales_count - used_sales_count - collectible_sales_count\n",
    "            \n",
    "            return total_sales_count, new_sales_count, used_sales_count, collectible_sales_count\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"è²©å£²æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "    def get_sales_data(self, product):\n",
    "        \"\"\"\n",
    "        å•†å“ã®è²©å£²æ•°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        product : dict\n",
    "            å•†å“æƒ…å ±\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            è²©å£²æ•°æƒ…å ±ã‚’å«ã‚€è¾æ›¸\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 30æ—¥ã€90æ—¥ã€180æ—¥ã®è²©å£²æ•°ã‚’è¨ˆç®—\n",
    "            sales_30 = self.calculate_sales(product, 30)\n",
    "            sales_90 = self.calculate_sales(product, 90)\n",
    "            sales_180 = self.calculate_sales(product, 180)\n",
    "\n",
    "            # Keepa APIã®çµ±è¨ˆæƒ…å ±ã‚‚å–å¾—ï¼ˆæ¯”è¼ƒç”¨ï¼‰\n",
    "            stats = product.get('stats', {})\n",
    "            \n",
    "            return {\n",
    "                # 30æ—¥ãƒ‡ãƒ¼ã‚¿\n",
    "                \"30æ—¥é–“_ç·è²©å£²æ•°\": sales_30[0],\n",
    "                \"30æ—¥é–“_æ–°å“è²©å£²æ•°\": sales_30[1],\n",
    "                \"30æ—¥é–“_ä¸­å¤è²©å£²æ•°\": sales_30[2],\n",
    "                \"30æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°\": sales_30[3],\n",
    "                \"Keepa30æ—¥é–“è²©å£²æ•°\": stats.get('salesRankDrops30', 0),\n",
    "\n",
    "                # 90æ—¥ãƒ‡ãƒ¼ã‚¿\n",
    "                \"90æ—¥é–“_ç·è²©å£²æ•°\": sales_90[0],\n",
    "                \"90æ—¥é–“_æ–°å“è²©å£²æ•°\": sales_90[1],\n",
    "                \"90æ—¥é–“_ä¸­å¤è²©å£²æ•°\": sales_90[2],\n",
    "                \"90æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°\": sales_90[3],\n",
    "                \"Keepa90æ—¥é–“è²©å£²æ•°\": stats.get('salesRankDrops90', 0),\n",
    "\n",
    "                # 180æ—¥ãƒ‡ãƒ¼ã‚¿\n",
    "                \"180æ—¥é–“_ç·è²©å£²æ•°\": sales_180[0],\n",
    "                \"180æ—¥é–“_æ–°å“è²©å£²æ•°\": sales_180[1],\n",
    "                \"180æ—¥é–“_ä¸­å¤è²©å£²æ•°\": sales_180[2],\n",
    "                \"180æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°\": sales_180[3],\n",
    "                \"Keepa180æ—¥é–“è²©å£²æ•°\": stats.get('salesRankDrops180', 0)\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"è²©å£²ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d322f-5cc1-4e48-8646-daaab3b58de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«5: CSVãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã¨ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "class KeepaProductAnalyzer(KeepaProductAnalyzer):\n",
    "    def load_asins_from_csv(self, input_file=None, asin_column='ASIN'):\n",
    "        \"\"\"\n",
    "        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ASINãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_file : str, optional\n",
    "            å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆçœç•¥æ™‚ã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä½¿ç”¨ï¼‰\n",
    "        asin_column : str\n",
    "            ASINåˆ—ã®åå‰\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list\n",
    "            ASINã®ãƒªã‚¹ãƒˆ\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®è¨­å®š\n",
    "            if input_file is None:\n",
    "                input_file = self.config['keepa_api']['output']['input_file']\n",
    "            elif not os.path.isabs(input_file):\n",
    "                # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«ã™ã‚‹\n",
    "                input_file = os.path.join(self.data_dir, input_file)\n",
    "                \n",
    "            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
    "            if not os.path.exists(input_file):\n",
    "                error_msg = f\"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}\"\n",
    "                logging.error(error_msg)\n",
    "                raise FileNotFoundError(error_msg)\n",
    "                \n",
    "            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "            df = pd.read_csv(input_file, encoding='utf-8-sig')\n",
    "            \n",
    "            # ASINåˆ—ã®å­˜åœ¨ç¢ºèª\n",
    "            if asin_column not in df.columns:\n",
    "                error_msg = f\"'{asin_column}'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\"\n",
    "                logging.error(error_msg)\n",
    "                raise ValueError(error_msg)\n",
    "                \n",
    "            # ASINãƒªã‚¹ãƒˆã®å–å¾—\n",
    "            asins = df[asin_column].dropna().unique().tolist()\n",
    "            logging.info(f\"{len(asins)}ä»¶ã®ASINã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "            print(f\"ğŸ“ {len(asins)}ä»¶ã®ASINã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "            print(f\"ğŸ“„ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {input_file}\")\n",
    "            \n",
    "            return asins\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"ASINã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}\"\n",
    "            logging.error(error_msg)\n",
    "            raise\n",
    "    \n",
    "    def save_to_csv(self, df, output_file=None, encoding='utf-8-sig'):\n",
    "        \"\"\"\n",
    "        DataFrameã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        output_file : str, optional\n",
    "            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆçœç•¥æ™‚ã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä½¿ç”¨ï¼‰\n",
    "        encoding : str\n",
    "            æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'utf-8-sig'ï¼‰\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®è¨­å®š\n",
    "            if output_file is None:\n",
    "                output_file = self.config['keepa_api']['output']['output_file']\n",
    "            elif not os.path.isabs(output_file):\n",
    "                # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«ã™ã‚‹\n",
    "                output_file = os.path.join(self.data_dir, output_file)\n",
    "                \n",
    "            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ\n",
    "            output_dir = os.path.dirname(output_file)\n",
    "            if output_dir and not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "                \n",
    "            # CSVã¨ã—ã¦ä¿å­˜\n",
    "            df.to_csv(output_file, index=False, encoding=encoding)\n",
    "            logging.info(f\"ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file} ({len(df)}ä»¶)\")\n",
    "            print(f\"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}\"\n",
    "            logging.error(error_msg)\n",
    "            print(f\"âŒ {error_msg}\")\n",
    "            raise\n",
    "    \n",
    "    def get_product_data(self, asin_list):\n",
    "        \"\"\"\n",
    "        ASINãƒªã‚¹ãƒˆã‹ã‚‰å•†å“æƒ…å ±ã‚’å–å¾—ã™ã‚‹\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        asin_list : list\n",
    "            ASINã®ãƒªã‚¹ãƒˆ\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            å•†å“æƒ…å ±ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        logging.info(f\"å•†å“æƒ…å ±ã®å–å¾—ã‚’é–‹å§‹: {len(asin_list)}ä»¶\")\n",
    "        \n",
    "        # 1. APIå‘¼ã³å‡ºã—ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n",
    "        products = self._call_api(asin_list)\n",
    "        if products is None:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # 2. ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—\n",
    "        product_data = []\n",
    "        for product in products:\n",
    "            try:\n",
    "                # åŸºæœ¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯\n",
    "                if not product.get('stats'):\n",
    "                    logging.warning(f\"å•†å“ãƒ‡ãƒ¼ã‚¿ãªã— (ASIN: {product.get('asin', 'ä¸æ˜')})\")\n",
    "                    continue\n",
    "\n",
    "                # å•†å“æƒ…å ±ã®å–å¾—ã¨çµ±åˆ\n",
    "                product_info = self._get_basic_info(product)\n",
    "                price_info = self._get_price_info(product)\n",
    "                rank_stock_info = self._get_rank_and_stock_info(product)\n",
    "                sales_info = self.get_sales_data(product)\n",
    "                \n",
    "                # å…¨ã¦ã®æƒ…å ±ã‚’çµ±åˆ\n",
    "                product_info.update(price_info)\n",
    "                product_info.update(rank_stock_info)\n",
    "                product_info.update(sales_info)\n",
    "                \n",
    "                # æ—¥ä»˜æƒ…å ±ã®è¿½åŠ \n",
    "                product_info[\"å•†å“è¿½è·¡æ—¥\"] = product.get('trackingSince', '')\n",
    "                product_info[\"å•†å“ç™ºå£²æ—¥\"] = None if product.get('releaseDate', -1) == -1 else product['releaseDate']\n",
    "                \n",
    "                tracking_since = product.get('trackingSince')\n",
    "                if tracking_since:\n",
    "                    try:\n",
    "                        unix_timestamp = (tracking_since + 21564000) * 60\n",
    "                        tracking_date = datetime.fromtimestamp(unix_timestamp)\n",
    "                        product_info[\"è¿½è·¡é–‹å§‹ã‹ã‚‰ã®çµŒéæ—¥æ•°\"] = (datetime.today() - tracking_date).days\n",
    "                    except Exception as e:\n",
    "                        logging.warning(f\"çµŒéæ—¥æ•°ã®è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "                        product_info[\"è¿½è·¡é–‹å§‹ã‹ã‚‰ã®çµŒéæ—¥æ•°\"] = None\n",
    "                else:\n",
    "                    product_info[\"è¿½è·¡é–‹å§‹ã‹ã‚‰ã®çµŒéæ—¥æ•°\"] = None\n",
    "                \n",
    "                product_data.append(product_info)\n",
    "                logging.debug(f\"å•†å“ãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ: {product_info['ASIN']}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"å•†å“ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ (ASIN: {product.get('asin', 'ä¸æ˜')}): {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # å¸Œæœ›ã™ã‚‹åˆ—ã®é †åºã‚’å®šç¾©\n",
    "        desired_columns = [\n",
    "            # åŸºæœ¬æƒ…å ±\n",
    "            \"ASIN\", \"JAN\", \"å•†å“å\", \"ã‚«ãƒ†ã‚´ãƒªãƒ¼\", \"ãƒ¡ãƒ¼ã‚«ãƒ¼å‹ç•ª\", \"ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ‰ç„¡\", \n",
    "            \"ãƒ¡ãƒ¼ã‚«ãƒ¼å\", \"ãƒ–ãƒ©ãƒ³ãƒ‰å\", \"ç·å‡ºå“è€…æ•°\", \"ã‚»ãƒƒãƒˆæ•°(Q)\", \"ã‚»ãƒƒãƒˆæ•°(N)\", \"å•†å“è¿½è·¡æ—¥\", \n",
    "            \"å•†å“ç™ºå£²æ—¥\", \"è¿½è·¡é–‹å§‹ã‹ã‚‰ã®çµŒéæ—¥æ•°\", \"ã‚¢ãƒ€ãƒ«ãƒˆå•†å“å¯¾è±¡\", \"ç”»åƒURL\",\n",
    "            \n",
    "            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»URLæƒ…å ±\n",
    "            \"30æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°\", \"90æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°\", \"180æ—¥é–“å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°\",\n",
    "            \"amazonURL\", \"KeepaURL\", \"ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ASIN\",\n",
    "            \n",
    "            # Amazonãƒ»åœ¨åº«æƒ…å ±\n",
    "            \"amazonæœ¬ä½“æœ‰ç„¡\", \"amazon_30æ—¥é–“åœ¨åº«åˆ‡ã‚Œç‡\", \"amazon_90æ—¥é–“åœ¨åº«åˆ‡ã‚Œç‡\",\n",
    "            \n",
    "            # ä¾¡æ ¼æƒ…å ±\n",
    "            \"amazonä¾¡æ ¼_ç¾åœ¨ä¾¡æ ¼\", \"amazonä¾¡æ ¼_æœ€é«˜ä¾¡æ ¼\", \"amazonä¾¡æ ¼_æœ€ä½ä¾¡æ ¼\",\n",
    "            \"amazonä¾¡æ ¼_30æ—¥å¹³å‡ä¾¡æ ¼\", \"amazonä¾¡æ ¼_90æ—¥å¹³å‡ä¾¡æ ¼\", \"amazonä¾¡æ ¼_180æ—¥å¹³å‡ä¾¡æ ¼\",\n",
    "            \"æ–°å“ä¾¡æ ¼_ç¾åœ¨ä¾¡æ ¼\", \"æ–°å“ä¾¡æ ¼_æœ€é«˜ä¾¡æ ¼\", \"æ–°å“ä¾¡æ ¼_æœ€ä½ä¾¡æ ¼\",\n",
    "            \"æ–°å“ä¾¡æ ¼_30æ—¥å¹³å‡ä¾¡æ ¼\", \"æ–°å“ä¾¡æ ¼_90æ—¥å¹³å‡ä¾¡æ ¼\", \"æ–°å“ä¾¡æ ¼_180æ—¥å¹³å‡ä¾¡æ ¼\",\n",
    "            \n",
    "            # è²©å£²æ•°æƒ…å ±\n",
    "            \"30æ—¥é–“_ç·è²©å£²æ•°\", \"30æ—¥é–“_æ–°å“è²©å£²æ•°\", \"30æ—¥é–“_ä¸­å¤è²©å£²æ•°\", \"30æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°\", \"Keepa30æ—¥é–“è²©å£²æ•°\",\n",
    "            \"90æ—¥é–“_ç·è²©å£²æ•°\", \"90æ—¥é–“_æ–°å“è²©å£²æ•°\", \"90æ—¥é–“_ä¸­å¤è²©å£²æ•°\", \"90æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°\", \"Keepa90æ—¥é–“è²©å£²æ•°\",\n",
    "            \"180æ—¥é–“_ç·è²©å£²æ•°\", \"180æ—¥é–“_æ–°å“è²©å£²æ•°\", \"180æ—¥é–“_ä¸­å¤è²©å£²æ•°\", \"180æ—¥é–“_ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼è²©å£²æ•°\", \"Keepa180æ—¥é–“è²©å£²æ•°\"\n",
    "        ]\n",
    "        \n",
    "        # DataFrameã®åˆ—ã‚’æŒ‡å®šã—ãŸé †åºã«ä¸¦ã³æ›¿ãˆ\n",
    "        df = pd.DataFrame(product_data)\n",
    "        \n",
    "        # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’æŠ½å‡ºï¼ˆã‚¨ãƒ©ãƒ¼é˜²æ­¢ã®ãŸã‚ï¼‰\n",
    "        valid_columns = [col for col in desired_columns if col in df.columns]\n",
    "        df = df[valid_columns]\n",
    "        \n",
    "        logging.info(f\"ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {len(product_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«å‡¦ç†\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e432ff7c-a480-46be-b837-eb4e342053a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«6: å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ï¼ˆãƒ†ã‚¹ãƒˆï¼‰\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ\n",
    "        analyzer = KeepaProductAnalyzer()\n",
    "        \n",
    "        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ASINã‚’èª­ã¿è¾¼ã¿ï¼ˆå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰\n",
    "        asins = analyzer.load_asins_from_csv()\n",
    "        print(f\"ğŸ“ {len(asins)}ä»¶ã®ASINã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "        print(f\"ğŸ“„ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {analyzer.config['keepa_api']['output']['input_file']}\")\n",
    "        \n",
    "        # å•†å“æƒ…å ±ã‚’å–å¾—\n",
    "        df = analyzer.get_product_data(asins)\n",
    "        \n",
    "        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ï¼ˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰\n",
    "        analyzer.save_to_csv(df)\n",
    "        print(f\"ğŸ“„ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {analyzer.config['keepa_api']['output']['output_file']}\")\n",
    "        \n",
    "        # çµæœã‚’è¡¨ç¤º\n",
    "        print(\"\\n=== å‡¦ç†çµæœã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®5ä»¶ï¼‰===\")\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        display(df.head())\n",
    "        \n",
    "        print(f\"\\nâœ¨ å‡¦ç†å®Œäº†ï¼ å…¨{len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\")\n",
    "        logging.error(f\"å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        traceback.print_exc()  # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’è¡¨ç¤ºã—ã¦åŸå› ã‚’ç‰¹å®šã—ã‚„ã™ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8b77a-3c68-4ac9-ad3d-38483f22ffd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
