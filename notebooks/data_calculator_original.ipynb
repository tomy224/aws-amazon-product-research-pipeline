{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd604196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–‹ç™ºéç¨‹ã®è£œè¶³\n",
    "\n",
    "# ã“ã® Jupyter Notebook ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€é–‹ç™ºéç¨‹ã‚’ç¤ºã™ãŸã‚ã«ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚  \n",
    "# ã‚»ãƒ«å˜ä½ã§ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ãªãŒã‚‰å‡¦ç†å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã€Œæ¤œè¨¼ç”¨ç’°å¢ƒã€ã¨ã—ã¦ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚  \n",
    "# å®Ÿéš›ã®æœ¬ç•ªç’°å¢ƒã§ã¯ VSCode ä¸Šã§ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã€AWS Lambda ãŠã‚ˆã³ Step Functions ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616fbf07-9654-4650-b555-90e0b6069291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«1: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88bace-d1fa-423a-bcc8-bc8b86344ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«2: è¨­å®šã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°\n",
    "class ProductCalculator:\n",
    "    \"\"\"\n",
    "    å•†å“ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦è¨ˆç®—å‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹\n",
    "    \n",
    "    çµ±åˆã•ã‚ŒãŸCSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€è¿½åŠ ã®è¨ˆç®—ãƒ»åˆ†æã‚’è¡Œã£ã¦\n",
    "    æ–°ã—ã„åˆ—ã‚’è¿½åŠ ã—ã€çµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_path=None):\n",
    "        \"\"\"\n",
    "        ProductCalculatorã®åˆæœŸåŒ–\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        config_path : str, optional\n",
    "            è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼‰\n",
    "        \"\"\"\n",
    "        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œå‡º\n",
    "        self.root_dir = self._find_project_root()\n",
    "        \n",
    "        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®è¨­å®š\n",
    "        self.data_dir = os.path.join(self.root_dir, 'data')\n",
    "        self.log_dir = os.path.join(self.root_dir, 'logs')\n",
    "        \n",
    "        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
    "        os.makedirs(self.data_dir, exist_ok=True)\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "        \n",
    "        # ãƒ­ã‚°ã®è¨­å®š\n",
    "        self.setup_logging()\n",
    "        \n",
    "        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "        self.config = self._load_config(config_path)\n",
    "        \n",
    "        # å…¥å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š\n",
    "        self.setup_file_paths()\n",
    "    \n",
    "    def _find_project_root(self):\n",
    "        \"\"\"\n",
    "        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œå‡ºã™ã‚‹\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹\n",
    "        \"\"\"\n",
    "        # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’å–å¾—\n",
    "        current_dir = os.path.abspath(os.getcwd())\n",
    "        \n",
    "        # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢\n",
    "        path = Path(current_dir)\n",
    "        while True:\n",
    "            # .gitãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Œã°ãã‚Œã‚’ãƒ«ãƒ¼ãƒˆã¨ã¿ãªã™\n",
    "            if (path / '.git').exists():\n",
    "                return str(path)\n",
    "            \n",
    "            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆã‚’ç¤ºã™ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯\n",
    "            if (path / 'README.md').exists():\n",
    "                return str(path)\n",
    "            \n",
    "            # ã“ã‚Œä»¥ä¸Šä¸Šã®éšå±¤ãŒãªã„å ´åˆã¯ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿”ã™\n",
    "            if path.parent == path:\n",
    "                return str(path)\n",
    "            \n",
    "            # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸\n",
    "            path = path.parent\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        \"\"\"ãƒ­ã‚°æ©Ÿèƒ½ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\"\"\"\n",
    "        # ã™ã¹ã¦ã®æ—¢å­˜ã®ãƒ­ã‚°ãƒãƒ³ãƒ‰ãƒ©ã‚’å‰Šé™¤\n",
    "        root_logger = logging.getLogger()\n",
    "        for handler in root_logger.handlers[:]:\n",
    "            root_logger.removeHandler(handler)\n",
    "        \n",
    "        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š\n",
    "        log_filename = f'product_calculator_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
    "        log_file = os.path.join(self.log_dir, log_filename)\n",
    "        \n",
    "        # åŸºæœ¬è¨­å®š - filehandlerã¨consolehandlerã‚’ä½¿ã£ã¦æ˜ç¤ºçš„ã«è¨­å®š\n",
    "        # logging.basicConfigã§ã¯ãªãã€å€‹åˆ¥ã«ãƒãƒ³ãƒ‰ãƒ©ã‚’è¿½åŠ \n",
    "        root_logger.setLevel(logging.INFO)\n",
    "        \n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©\n",
    "        file_handler = logging.FileHandler(log_file, encoding='utf-8')\n",
    "        file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(file_formatter)\n",
    "        root_logger.addHandler(file_handler)\n",
    "        \n",
    "        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setLevel(logging.INFO)\n",
    "        console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        console_handler.setFormatter(console_formatter)\n",
    "        root_logger.addHandler(console_handler)\n",
    "        \n",
    "        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€ã‚’æ˜ç¤ºçš„ã«è¡¨ç¤º - é€šå¸¸ã®printã§\n",
    "        print(f\"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›å…ˆ: {log_file}\")\n",
    "        # ã“ã“ã§ä¸€åº¦ã ã‘ãƒ­ã‚°è¨˜éŒ²\n",
    "        logging.info(f\"ãƒ­ã‚°æ©Ÿèƒ½ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ: {log_file}\")\n",
    "    \n",
    "    def _load_config(self, config_path=None):\n",
    "        \"\"\"\n",
    "        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        config_path : str, optional\n",
    "            è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            è¨­å®šãƒ‡ãƒ¼ã‚¿\n",
    "        \"\"\"\n",
    "        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ã‚¹\n",
    "        if config_path is None:\n",
    "            config_path = os.path.join(self.root_dir, 'config', 'settings.yaml')\n",
    "        \n",
    "        print(f\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {config_path}\")\n",
    "        \n",
    "        try:\n",
    "            if not os.path.exists(config_path):\n",
    "                raise FileNotFoundError(f\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}\")\n",
    "                \n",
    "            # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "            with open(config_path, 'r', encoding='utf-8') as f:\n",
    "                config = yaml.safe_load(f)\n",
    "            \n",
    "            # è¨ˆç®—æ©Ÿèƒ½ã®è¨­å®šç¢ºèª\n",
    "            if 'calculator' not in config:\n",
    "                config['calculator'] = {}\n",
    "            \n",
    "            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å‡ºåŠ›è¨­å®šï¼ˆãªã‘ã‚Œã°è¨­å®šï¼‰\n",
    "            if 'output' not in config['calculator']:\n",
    "                config['calculator']['output'] = {\n",
    "                    'input_file': 'integrated_data.csv',\n",
    "                    'output_file': 'calculated_data.csv'\n",
    "                }\n",
    "            \n",
    "            print(\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "            return config\n",
    "        except Exception as e:\n",
    "            logging.error(f\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def setup_file_paths(self):\n",
    "        \"\"\"å…¥å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š\"\"\"\n",
    "        # è¨­å®šã‹ã‚‰å…¥å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—\n",
    "        input_filename = self.config['calculator']['output'].get('input_file', 'integrated_data.csv')\n",
    "        output_filename = self.config['calculator']['output'].get('output_file', 'calculated_data.csv')\n",
    "        \n",
    "        # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›\n",
    "        if not os.path.isabs(input_filename):\n",
    "            self.input_file = os.path.join(self.data_dir, input_filename)\n",
    "        else:\n",
    "            self.input_file = input_filename\n",
    "            \n",
    "        if not os.path.isabs(output_filename):\n",
    "            self.output_file = os.path.join(self.data_dir, output_filename)\n",
    "        else:\n",
    "            self.output_file = output_filename\n",
    "        \n",
    "        logging.info(f\"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {self.input_file}\")\n",
    "        logging.info(f\"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {self.output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40737d22-bc34-42b6-9611-cad517a86dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«3: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨åŸºæœ¬è¨ˆç®—æ©Ÿèƒ½\n",
    "class ProductCalculator(ProductCalculator):\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
    "            if not os.path.exists(self.input_file):\n",
    "                raise FileNotFoundError(f\"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.input_file}\")\n",
    "            \n",
    "            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "            df = pd.read_csv(self.input_file, encoding='utf-8-sig')\n",
    "            \n",
    "            logging.info(f\"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(df)}è¡Œ, {len(df.columns)}åˆ—\")\n",
    "            print(f\"ğŸ“Š {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "            \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def save_data(self, df):\n",
    "        \"\"\"\n",
    "        è¨ˆç®—çµæœã‚’CSVã¨ã—ã¦ä¿å­˜\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª\n",
    "            output_dir = os.path.dirname(self.output_file)\n",
    "            if output_dir and not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            \n",
    "            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚³ãƒ”ãƒ¼\n",
    "            output_df = df.copy()\n",
    "            \n",
    "            # ä¸è¦ãªåˆ—ã‚’é™¤å¤–\n",
    "            # ã€Œãƒãƒƒã‚·ãƒ¼_ã€ã€Œã‚¹ãƒ¼ãƒ‡ãƒª_ã€ã€Œãƒ¤ãƒ•ãƒ¼_ã€ã€Œãƒ¨ãƒªãƒ¤ã‚¹_ã€ã§å§‹ã¾ã‚‹åˆ—ã‚’é™¤å¤–\n",
    "            columns_to_drop = [col for col in output_df.columns if \n",
    "                             col.startswith('ãƒãƒƒã‚·ãƒ¼_') or \n",
    "                             col.startswith('ã‚¹ãƒ¼ãƒ‡ãƒª_') or \n",
    "                             col.startswith('ãƒ¤ãƒ•ãƒ¼_') or \n",
    "                             col.startswith('ãƒ¨ãƒªãƒ¤ã‚¹_')]\n",
    "            \n",
    "            if columns_to_drop:\n",
    "                # ä¸è¦ãªåˆ—ã‚’å‰Šé™¤\n",
    "                output_df = output_df.drop(columns=columns_to_drop)\n",
    "                logging.info(f\"{len(columns_to_drop)}åˆ—ã®ä»•å…¥ã‚Œã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ã¾ã—ãŸ\")\n",
    "                print(f\"â„¹ï¸ {len(columns_to_drop)}åˆ—ã®ä»•å…¥ã‚Œã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "            # CSVã¨ã—ã¦ä¿å­˜\n",
    "            output_df.to_csv(self.output_file, index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            logging.info(f\"ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {self.output_file} ({len(output_df)}è¡Œ, {len(output_df.columns)}åˆ—)\")\n",
    "            print(f\"âœ… {len(output_df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ {self.output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def add_calculation_columns(self, df):\n",
    "        \"\"\"\n",
    "        è¨ˆç®—åˆ—ã‚’è¿½åŠ ã™ã‚‹\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            åˆ—ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ãªã„ãŸã‚ï¼‰\n",
    "            result_df = df.copy()\n",
    "            \n",
    "            # ã“ã“ã«è¨ˆç®—å‡¦ç†ã‚’å®Ÿè£…ã—ã¦ã„ãã¾ã™\n",
    "            # === åŸºæœ¬çš„ãªè¨ˆç®—å‡¦ç†ã®ä¾‹ ===\n",
    "\n",
    "            # è²©å£²ä¾¡æ ¼ã®åˆè¨ˆè¨ˆç®—\n",
    "            # ã‚«ãƒ¼ãƒˆè²©å£²ä¾¡æ ¼ã®åˆè¨ˆ\n",
    "            if 'ã‚«ãƒ¼ãƒˆä¾¡æ ¼' in result_df.columns:\n",
    "                result_df['è²©å£²ä¾¡æ ¼_ã‚«ãƒ¼ãƒˆåˆè¨ˆ'] = result_df['ã‚«ãƒ¼ãƒˆä¾¡æ ¼'].fillna(0) + result_df['ã‚«ãƒ¼ãƒˆä¾¡æ ¼é€æ–™'].fillna(0) + result_df['ã‚«ãƒ¼ãƒˆä¾¡æ ¼ã®ãƒã‚¤ãƒ³ãƒˆ'].fillna(0)\n",
    "            \n",
    "            # FBAè²©å£²ä¾¡æ ¼ã®åˆè¨ˆ\n",
    "            if 'FBAæœ€å®‰å€¤' in result_df.columns:\n",
    "                result_df['è²©å£²ä¾¡æ ¼_FBAåˆè¨ˆ'] = result_df['FBAæœ€å®‰å€¤'].fillna(0) + result_df['FBAæœ€å®‰å€¤ã®ãƒã‚¤ãƒ³ãƒˆ'].fillna(0)\n",
    "            \n",
    "            # è‡ªå·±ç™ºé€è²©å£²ä¾¡æ ¼ã®åˆè¨ˆ\n",
    "            if 'è‡ªå·±ç™ºé€æœ€å®‰å€¤' in result_df.columns:\n",
    "                result_df['è²©å£²ä¾¡æ ¼_è‡ªå·±ç™ºåˆè¨ˆ'] = result_df['è‡ªå·±ç™ºé€æœ€å®‰å€¤'].fillna(0) + result_df['è‡ªå·±ç™ºé€æœ€å®‰å€¤ã®é€æ–™'].fillna(0) + result_df['è‡ªå·±ç™ºé€æœ€å®‰å€¤ã®ãƒã‚¤ãƒ³ãƒˆ'].fillna(0)\n",
    "\n",
    "            # æœ€å°è²©å£²ä¾¡æ ¼ï¼ˆã‚«ãƒ¼ãƒˆãƒ»FBAãƒ»è‡ªå·±ç™ºé€ã®ã†ã¡ã€0ã‚ˆã‚Šå¤§ãã„å€¤ã®æœ€å°å€¤ï¼‰\n",
    "            if 'ã‚«ãƒ¼ãƒˆä¾¡æ ¼' in result_df.columns:\n",
    "                result_df['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡'] = result_df[['è²©å£²ä¾¡æ ¼_ã‚«ãƒ¼ãƒˆåˆè¨ˆ', 'è²©å£²ä¾¡æ ¼_FBAåˆè¨ˆ', 'è²©å£²ä¾¡æ ¼_è‡ªå·±ç™ºåˆè¨ˆ']].replace(0, np.nan).min(axis=1)\n",
    "            \n",
    "            # ã‚µã‚¤ã‚ºã®è¨ˆç®—\n",
    "            # ã‚µã‚¤ã‚º_åˆè¨ˆcmï¼ˆä¸‰è¾ºã®åˆè¨ˆï¼‰\n",
    "            if 'ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€é•·è¾º' in result_df.columns:\n",
    "                result_df['ã‚µã‚¤ã‚º_åˆè¨ˆcm'] = result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€é•·è¾º'].fillna(0) + result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸­è¾º'].fillna(0) + result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€çŸ­è¾º'].fillna(0)\n",
    "            \n",
    "            # ã‚µã‚¤ã‚º_åˆè¨ˆcm3ï¼ˆä½“ç©ï¼‰\n",
    "            if 'ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€é•·è¾º' in result_df.columns:\n",
    "                result_df['ã‚µã‚¤ã‚º_åˆè¨ˆcm3'] = result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€é•·è¾º'].fillna(0) * result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸­è¾º'].fillna(0) * result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€çŸ­è¾º'].fillna(0)\n",
    "\n",
    "            # ã‚µã‚¤ã‚º_å°å‹æ¨™æº–åˆ¤å®šï¼ˆå°å‹æ¨™æº–ã‚µã‚¤ã‚ºã®åˆ¤å®šï¼‰\n",
    "            if 'ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€é•·è¾º' in result_df.columns and 'ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é‡é‡' in result_df.columns:\n",
    "                result_df['ã‚µã‚¤ã‚º_å°å‹æ¨™æº–åˆ¤å®š'] = np.where((result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€é•·è¾º'].fillna(0) <= 25) & (result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸­è¾º'].fillna(0) <= 18) & (result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€çŸ­è¾º'].fillna(0) <= 2) & (result_df['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é‡é‡'].fillna(0) <= 250), 'å¯¾è±¡', 'å¯¾è±¡å¤–')\n",
    "\n",
    "\n",
    "            # å‡ºå“è€…_amazonï¼ˆAmazonãŒå‡ºå“ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã®åˆ¤å®šï¼‰\n",
    "            if 'Amazonä¾¡æ ¼' in result_df.columns:\n",
    "                result_df['å‡ºå“è€…_amazon'] = np.where(result_df['Amazonä¾¡æ ¼'].fillna(0) >= 1, 'æœ‰', 'ç„¡')\n",
    "\n",
    "\n",
    "                        \n",
    "            logging.info(f\"è¨ˆç®—å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ: {len(result_df.columns) - len(df.columns)}åˆ—è¿½åŠ \")\n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"è¨ˆç®—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b52036-1813-4aa5-8874-19dac8139f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«4: JSONãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªè¨ˆç®—æ©Ÿèƒ½\n",
    "class ProductCalculator(ProductCalculator):\n",
    "    def load_json_data(self, json_file_path):\n",
    "        \"\"\"\n",
    "        JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        json_file_path : str\n",
    "            JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            JSONãƒ‡ãƒ¼ã‚¿\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(json_file_path):\n",
    "                logging.warning(f\"JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_file_path}\")\n",
    "                return {}\n",
    "            \n",
    "            with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            logging.info(f\"JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {json_file_path}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"JSONãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            return {}\n",
    "    \n",
    "    def add_json_based_calculations(self, df, json_data):\n",
    "        \"\"\"\n",
    "        JSONå‚ç…§ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãè¨ˆç®—ã‚’è¿½åŠ \n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        json_data : dict\n",
    "            å‚ç…§ç”¨JSONãƒ‡ãƒ¼ã‚¿\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            åˆ—ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ\n",
    "            result_df = df.copy()\n",
    "            \n",
    "            # JSONãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆã¯å‡¦ç†ã—ãªã„\n",
    "            if not json_data:\n",
    "                logging.warning(\"JSONãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚JSONå‚ç…§ã«ã‚ˆã‚‹è¨ˆç®—ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "                return result_df\n",
    "            \n",
    "            # ä¾‹: JSONãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸã‚«ãƒ†ã‚´ãƒªã‚³ãƒ¼ãƒ‰â†’ã‚«ãƒ†ã‚´ãƒªåã®å¤‰æ›\n",
    "            if 'ã‚«ãƒ†ã‚´ãƒªãƒ¼' in result_df.columns and 'categories' in json_data:\n",
    "                # ã‚«ãƒ†ã‚´ãƒªã‚³ãƒ¼ãƒ‰ã‚’ã‚­ãƒ¼ã€ã‚«ãƒ†ã‚´ãƒªåã‚’å€¤ã¨ã—ãŸè¾æ›¸ã‚’ä½œæˆ\n",
    "                category_map = {str(item['id']): item['name'] for item in json_data.get('categories', [])}\n",
    "                \n",
    "                # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨\n",
    "                result_df['ã‚«ãƒ†ã‚´ãƒªå'] = result_df['ã‚«ãƒ†ã‚´ãƒªãƒ¼'].astype(str).map(category_map)\n",
    "                logging.info(\"'ã‚«ãƒ†ã‚´ãƒªå'åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "                \n",
    "            # ä¾‹: å•†å“ã®å­£ç¯€æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆJSONã‹ã‚‰ã®æƒ…å ±ã«åŸºã¥ãï¼‰\n",
    "            if 'ASIN' in result_df.columns and 'seasonal_scores' in json_data:\n",
    "                # ASINã‚’ã‚­ãƒ¼ã¨ã—ãŸå­£ç¯€æ€§ã‚¹ã‚³ã‚¢ã®è¾æ›¸ã‚’ä½œæˆ\n",
    "                seasonal_map = json_data.get('seasonal_scores', {})\n",
    "                \n",
    "                # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨\n",
    "                result_df['å­£ç¯€æ€§ã‚¹ã‚³ã‚¢'] = result_df['ASIN'].map(seasonal_map)\n",
    "                \n",
    "                # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š\n",
    "                result_df['å­£ç¯€æ€§ã‚¹ã‚³ã‚¢'] = result_df['å­£ç¯€æ€§ã‚¹ã‚³ã‚¢'].fillna(0)\n",
    "                logging.info(\"'å­£ç¯€æ€§ã‚¹ã‚³ã‚¢'åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "            # ä¾‹: å•†å“ã®è¤‡é›‘ãªã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆJSONã‹ã‚‰ã®éšå±¤æƒ…å ±ã«åŸºã¥ãï¼‰\n",
    "            if 'ã‚«ãƒ†ã‚´ãƒªãƒ¼' in result_df.columns and 'category_hierarchy' in json_data:\n",
    "                category_hierarchy = json_data.get('category_hierarchy', {})\n",
    "                \n",
    "                # ã‚«ãƒ†ã‚´ãƒªéšå±¤æƒ…å ±ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "                def get_category_hierarchy(category_id):\n",
    "                    category_id = str(category_id)\n",
    "                    if category_id in category_hierarchy:\n",
    "                        return category_hierarchy[category_id]\n",
    "                    return []\n",
    "                \n",
    "                # éšå±¤æƒ…å ±ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦è¿½åŠ \n",
    "                result_df['ã‚«ãƒ†ã‚´ãƒªéšå±¤'] = result_df['ã‚«ãƒ†ã‚´ãƒªãƒ¼'].astype(str).apply(get_category_hierarchy)\n",
    "                \n",
    "                # å¿…è¦ã«å¿œã˜ã¦éšå±¤æƒ…å ±ã‹ã‚‰ç‰¹å®šã®éšå±¤ã‚’æŠ½å‡º\n",
    "                result_df['ã‚«ãƒ†ã‚´ãƒªL1'] = result_df['ã‚«ãƒ†ã‚´ãƒªéšå±¤'].apply(lambda x: x[0] if len(x) > 0 else \"\")\n",
    "                result_df['ã‚«ãƒ†ã‚´ãƒªL2'] = result_df['ã‚«ãƒ†ã‚´ãƒªéšå±¤'].apply(lambda x: x[1] if len(x) > 1 else \"\")\n",
    "                \n",
    "                # ãƒªã‚¹ãƒˆå½¢å¼ã®ã‚«ãƒ©ãƒ ã¯ä½¿ã„ã«ãã„ã®ã§å‰Šé™¤\n",
    "                result_df = result_df.drop('ã‚«ãƒ†ã‚´ãƒªéšå±¤', axis=1)\n",
    "                \n",
    "                logging.info(\"ã‚«ãƒ†ã‚´ãƒªéšå±¤æƒ…å ±ã®åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "            logging.info(f\"JSONå‚ç…§ã«ã‚ˆã‚‹è¨ˆç®—å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"JSONå‚ç…§ã«ã‚ˆã‚‹è¨ˆç®—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã§ãã‚‹ã ã‘å‡¦ç†ã‚’ç¶šè¡Œ\n",
    "            return df\n",
    "\n",
    "    def add_size_calculations(self, df):\n",
    "        \"\"\"\n",
    "        ã‚µã‚¤ã‚ºã«é–¢ã™ã‚‹è¨ˆç®—ã‚’è¡Œã†ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "        JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚µã‚¤ã‚ºåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ã‚µã‚¤ã‚ºåˆ¤å®šã‚’è¡Œã„ã¾ã™\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            åˆ—ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ\n",
    "            result_df = df.copy()\n",
    "            \n",
    "            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚µã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€\n",
    "            json_file_path = os.path.join(self.root_dir, 'config', 'shipping_size_data.json')\n",
    "            if not os.path.exists(json_file_path):\n",
    "                logging.warning(f\"ã‚µã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_file_path}\")\n",
    "                return result_df\n",
    "            \n",
    "            with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "                size_data = json.load(f)\n",
    "            \n",
    "            # ã‚µã‚¤ã‚ºåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "            size_categories = size_data.get('ã‚µã‚¤ã‚ºåŒºåˆ†', {})\n",
    "            \n",
    "            # åœ¨åº«ä¿ç®¡æ‰‹æ•°æ–™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "            storage_fees = size_data.get('åœ¨åº«ä¿ç®¡æ‰‹æ•°æ–™', {})\n",
    "            \n",
    "            # ã‚µã‚¤ã‚ºåˆ¤å®šé–¢æ•°\n",
    "            def determine_size_category(row):\n",
    "                # ã‚µã‚¤ã‚ºã¨é‡é‡æƒ…å ±ã‚’å–å¾—\n",
    "                sum_of_edges = row['ã‚µã‚¤ã‚º_åˆè¨ˆcm'] if pd.notna(row['ã‚µã‚¤ã‚º_åˆè¨ˆcm']) else 0\n",
    "                longest_edge = row['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€é•·è¾º'] if pd.notna(row['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€é•·è¾º']) else 0\n",
    "                middle_edge = row['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸­è¾º'] if pd.notna(row['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸­è¾º']) else 0\n",
    "                shortest_edge = row['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€çŸ­è¾º'] if pd.notna(row['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ€çŸ­è¾º']) else 0\n",
    "                weight = row['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é‡é‡'] if pd.notna(row['ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é‡é‡']) else 0\n",
    "                \n",
    "                # ã‚µã‚¤ã‚ºåŒºåˆ†ä¸Šé™ã‚’å–å¾—\n",
    "                size_limits = size_data.get('ã‚µã‚¤ã‚ºåŒºåˆ†ä¸Šé™', {})\n",
    "                \n",
    "                # ä¸»è¦ã‚«ãƒ†ã‚´ãƒªã®åˆ¤å®šï¼ˆå°å‹ã‹ã‚‰é †ã«åˆ¤å®šï¼‰\n",
    "                if (weight <= size_limits['å°å‹']['æœ€å¤§é‡é‡'] and \n",
    "                    sum_of_edges <= size_limits['å°å‹']['æœ€å¤§å¯¸æ³•']['ä¸‰è¾ºåˆè¨ˆ'] and\n",
    "                    longest_edge <= size_limits['å°å‹']['æœ€å¤§å¯¸æ³•']['æœ€é•·è¾º'] and\n",
    "                    middle_edge <= size_limits['å°å‹']['æœ€å¤§å¯¸æ³•']['ä¸­è¾º'] and\n",
    "                    shortest_edge <= size_limits['å°å‹']['æœ€å¤§å¯¸æ³•']['æœ€çŸ­è¾º']):\n",
    "                    main_category = \"å°å‹\"\n",
    "                elif (weight <= size_limits['æ¨™æº–']['æœ€å¤§é‡é‡'] and \n",
    "                      sum_of_edges <= size_limits['æ¨™æº–']['æœ€å¤§å¯¸æ³•']['ä¸‰è¾ºåˆè¨ˆ'] and\n",
    "                      longest_edge <= size_limits['æ¨™æº–']['æœ€å¤§å¯¸æ³•']['æœ€é•·è¾º'] and\n",
    "                      middle_edge <= size_limits['æ¨™æº–']['æœ€å¤§å¯¸æ³•']['ä¸­è¾º'] and\n",
    "                      shortest_edge <= size_limits['æ¨™æº–']['æœ€å¤§å¯¸æ³•']['æœ€çŸ­è¾º']):\n",
    "                    main_category = \"æ¨™æº–\"\n",
    "                elif (weight <= size_limits['å¤§å‹']['æœ€å¤§é‡é‡'] and \n",
    "                      sum_of_edges <= size_limits['å¤§å‹']['æœ€å¤§å¯¸æ³•']['ä¸‰è¾ºåˆè¨ˆ']):\n",
    "                    main_category = \"å¤§å‹\"\n",
    "                elif (weight <= size_limits['ç‰¹å¤§å‹']['æœ€å¤§é‡é‡'] and \n",
    "                      sum_of_edges <= size_limits['ç‰¹å¤§å‹']['æœ€å¤§å¯¸æ³•']['ä¸‰è¾ºåˆè¨ˆ']):\n",
    "                    main_category = \"ç‰¹å¤§å‹\"\n",
    "                else:\n",
    "                    return \"å¯¾è±¡å¤–\"\n",
    "                \n",
    "                # è©³ç´°ã‚µã‚¤ã‚ºåŒºåˆ†ã®åˆ¤å®š\n",
    "                matching_categories = [name for name, data in size_categories.items() \n",
    "                                      if name.startswith(main_category) and\n",
    "                                      weight <= data.get('é‡é‡', float('inf')) and\n",
    "                                      ((('æœ€é•·è¾º' in data.get('å¯¸æ³•', {}) and\n",
    "                                         longest_edge <= data['å¯¸æ³•']['æœ€é•·è¾º'] and\n",
    "                                         middle_edge <= data['å¯¸æ³•'].get('ä¸­è¾º', float('inf')) and\n",
    "                                         shortest_edge <= data['å¯¸æ³•'].get('æœ€çŸ­è¾º', float('inf')))) or\n",
    "                                       (('ä¸‰è¾ºåˆè¨ˆ' in data.get('å¯¸æ³•', {}) and\n",
    "                                         sum_of_edges <= data['å¯¸æ³•']['ä¸‰è¾ºåˆè¨ˆ'])))]\n",
    "                \n",
    "                # è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯æœ€åˆã®ã‚‚ã®ã‚’è¿”ã™\n",
    "                return matching_categories[0] if matching_categories else main_category\n",
    "            \n",
    "            # æœˆé¡ä¿ç®¡æ–™ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°\n",
    "            def calculate_storage_fee(row):\n",
    "                # ä½“ç©æƒ…å ±ã‚’å–å¾—\n",
    "                volume_cm3 = row['ã‚µã‚¤ã‚º_åˆè¨ˆcm3'] if pd.notna(row['ã‚µã‚¤ã‚º_åˆè¨ˆcm3']) else 0\n",
    "                \n",
    "                # ã‚µã‚¤ã‚ºã‚«ãƒ†ã‚´ãƒªã‚’å–å¾—\n",
    "                size_category = row['ã‚µã‚¤ã‚º_å¤§ãã•'] if pd.notna(row['ã‚µã‚¤ã‚º_å¤§ãã•']) else \"å¯¾è±¡å¤–\"\n",
    "                \n",
    "                # ã‚µã‚¤ã‚ºã‚«ãƒ†ã‚´ãƒªãŒå¯¾è±¡å¤–ã¾ãŸã¯æœªå®šç¾©ã®å ´åˆ\n",
    "                if size_category == \"å¯¾è±¡å¤–\":\n",
    "                    return None\n",
    "                \n",
    "                # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªï¼ˆå°å‹ã€æ¨™æº–ã€å¤§å‹ã€ç‰¹å¤§å‹ï¼‰ã‚’æŠ½å‡º\n",
    "                main_category = size_category.split('-')[0] if '-' in size_category else size_category\n",
    "                \n",
    "                # è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã®ä¿ç®¡æ–™å˜ä¾¡ã‚’å–å¾—\n",
    "                if main_category in storage_fees:\n",
    "                    fee_rate = storage_fees[main_category].get('å˜ä¾¡', 0)\n",
    "                    \n",
    "                    # 1000cm3ã‚ãŸã‚Šã®æ–™é‡‘ã§è¨ˆç®—\n",
    "                    storage_fee = fee_rate * (volume_cm3 / 1000)\n",
    "                    \n",
    "                    # å°æ•°ç‚¹ä»¥ä¸‹ã‚’å››æ¨äº”å…¥ã—ã¦æ•´æ•°ã«\n",
    "                    return round(storage_fee)\n",
    "                \n",
    "                return None\n",
    "            \n",
    "            # ã‚µã‚¤ã‚ºåŒºåˆ†ã‚’åˆ¤å®šã—ã¦åˆ—ã«è¿½åŠ \n",
    "            result_df['ã‚µã‚¤ã‚º_å¤§ãã•'] = result_df.apply(determine_size_category, axis=1)\n",
    "            \n",
    "            # æœˆé¡ä¿ç®¡æ–™ã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ \n",
    "            result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_æœˆé¡ä¿ç®¡æ–™'] = result_df.apply(calculate_storage_fee, axis=1)\n",
    "            \n",
    "            # é…é€ä»£è¡Œæ‰‹æ•°æ–™ã®è¨ˆç®—\n",
    "            if 'ã‚µã‚¤ã‚º_å¤§ãã•' in result_df.columns and 'è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡' in result_df.columns:\n",
    "                # æ‰‹æ•°æ–™ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°\n",
    "                def calculate_shipping_fee(row):\n",
    "                    size_category = row['ã‚µã‚¤ã‚º_å¤§ãã•']\n",
    "                    price = row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡'] if pd.notna(row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡']) else 0\n",
    "                    \n",
    "                    # ã‚µã‚¤ã‚ºã‚«ãƒ†ã‚´ãƒªãŒå¯¾è±¡å¤–ã¾ãŸã¯å­˜åœ¨ã—ãªã„å ´åˆ\n",
    "                    if size_category == \"å¯¾è±¡å¤–\" or size_category not in size_categories:\n",
    "                        return None\n",
    "                    \n",
    "                    # ä¾¡æ ¼ã«å¿œã˜ãŸæ‰‹æ•°æ–™ã‚’å–å¾—\n",
    "                    fee_data = size_categories[size_category].get('é…é€ä»£è¡Œæ‰‹æ•°æ–™', {})\n",
    "                    if price <= 1000:\n",
    "                        return fee_data.get('1000å††ä»¥ä¸‹', None)\n",
    "                    else:\n",
    "                        return fee_data.get('1000å††è¶…', None)\n",
    "                \n",
    "                # é…é€ä»£è¡Œæ‰‹æ•°æ–™ã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ \n",
    "                result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_ç™ºé€ä»£è¡Œæ‰‹æ•°æ–™'] = result_df.apply(calculate_shipping_fee, axis=1)\n",
    "            \n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"ã‚µã‚¤ã‚ºè¨ˆç®—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            logging.error(traceback.format_exc())  # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å‡ºåŠ›\n",
    "            return df\n",
    "\n",
    "\n",
    "    def add_category_calculations(self, df):\n",
    "        \"\"\"\n",
    "        ã‚«ãƒ†ã‚´ãƒªã«é–¢ã™ã‚‹è¨ˆç®—ã‚’è¡Œã†ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "        JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã¨è²©å£²æ‰‹æ•°æ–™ç‡ã‚’è¿½åŠ ã—ã¾ã™\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            åˆ—ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ\n",
    "            result_df = df.copy()\n",
    "            \n",
    "            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€\n",
    "            json_file_path = os.path.join(self.root_dir, 'config', 'category_data.json')\n",
    "            if not os.path.exists(json_file_path):\n",
    "                logging.warning(f\"ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_file_path}\")\n",
    "                return result_df\n",
    "            \n",
    "            with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "                category_data = json.load(f)\n",
    "            \n",
    "            # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "            category_mapping = category_data.get('ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°', {})\n",
    "            \n",
    "            # ã‚«ãƒ†ã‚´ãƒªIDã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªåã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆï¼ˆé€†å¼•ãç”¨ï¼‰\n",
    "            category_id_to_name = {}\n",
    "            for category_name, info in category_mapping.items():\n",
    "                category_id = info.get('keepaã‚«ãƒ†ã‚´ãƒªID')\n",
    "                if category_id:\n",
    "                    category_id_to_name[category_id] = category_name\n",
    "            \n",
    "            # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã¨ã‚«ãƒ†ã‚´ãƒªåã‹ã‚‰è²©å£²æ‰‹æ•°æ–™ç‡ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°\n",
    "            def get_category_info_and_fee_rate(row):\n",
    "                # ã‚«ãƒ†ã‚´ãƒªIDã‚’å–å¾—\n",
    "                category_id = str(row['ã‚«ãƒ†ã‚´ãƒªãƒ¼']) if pd.notna(row['ã‚«ãƒ†ã‚´ãƒªãƒ¼']) else ''\n",
    "                \n",
    "                # ã‚«ãƒ†ã‚´ãƒªIDã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªåã‚’å–å¾—\n",
    "                category_name = category_id_to_name.get(category_id, 'ä¸æ˜')\n",
    "                \n",
    "                # è²©å£²ä¾¡æ ¼ã‚’å–å¾—\n",
    "                price = row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡'] if pd.notna(row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡']) else 0\n",
    "                \n",
    "                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š\n",
    "                fee_rate = None\n",
    "                fee_category = \"ä¸æ˜\"\n",
    "                media_fee = None  # ãƒ¡ãƒ‡ã‚£ã‚¢æ‰‹æ•°æ–™ã®åˆæœŸå€¤\n",
    "                \n",
    "                # ã‚«ãƒ†ã‚´ãƒªåã«è©²å½“ã™ã‚‹æƒ…å ±ãŒã‚ã‚‹å ´åˆ\n",
    "                if category_name in category_mapping:\n",
    "                    category_info = category_mapping[category_name]\n",
    "                    fee_category = category_info.get('è²©å£²æ‰‹æ•°æ–™ã‚«ãƒ†ã‚´ãƒª', \"ä¸æ˜\")\n",
    "                    fee_rates = category_info.get('è²©å£²æ‰‹æ•°æ–™ç‡', [])\n",
    "                    \n",
    "                    # ãƒ¡ãƒ‡ã‚£ã‚¢æ‰‹æ•°æ–™ã‚’å–å¾—ã—ã€ã‚ã‚Œã°æ¶ˆè²»ç¨(10%)ã‚’åŠ ç®—\n",
    "                    base_media_fee = category_info.get('ãƒ¡ãƒ‡ã‚£ã‚¢æ‰‹æ•°æ–™')\n",
    "                    if base_media_fee is not None:\n",
    "                        media_fee = base_media_fee * 1.1  # æ¶ˆè²»ç¨ã‚’åŠ ç®—\n",
    "                        media_fee = round(media_fee)  # å››æ¨äº”å…¥ã—ã¦æ•´æ•°ã«\n",
    "                    \n",
    "                    # ä¾¡æ ¼ã«å¿œã˜ãŸæ‰‹æ•°æ–™ç‡ã‚’æ±ºå®š\n",
    "                    if isinstance(fee_rates, list):\n",
    "                        # é…åˆ—å½¢å¼ã®å ´åˆï¼ˆæ–°å½¢å¼ï¼‰\n",
    "                        for rate_info in fee_rates:\n",
    "                            upper_limit = rate_info.get('ä¸Šé™é‡‘é¡')\n",
    "                            if upper_limit is None or price <= upper_limit:\n",
    "                                fee_rate = rate_info.get('æ–™ç‡')\n",
    "                                break\n",
    "                    elif isinstance(fee_rates, dict):\n",
    "                        # è¾æ›¸å½¢å¼ã®å ´åˆï¼ˆæ—§å½¢å¼ - äº’æ›æ€§ã®ãŸã‚ï¼‰\n",
    "                        if price <= 750 and '750å††ä»¥ä¸‹' in fee_rates:\n",
    "                            fee_rate = fee_rates['750å††ä»¥ä¸‹']\n",
    "                        elif 750 < price <= 1500 and '750å††è¶… 1500å††ä»¥ä¸‹' in fee_rates:\n",
    "                            fee_rate = fee_rates['750å††è¶… 1500å††ä»¥ä¸‹']\n",
    "                        elif price > 1500 and '1500å††è¶…' in fee_rates:\n",
    "                            fee_rate = fee_rates['1500å††è¶…']\n",
    "                        elif '750å††è¶…' in fee_rates and price > 750:\n",
    "                            fee_rate = fee_rates['750å††è¶…']\n",
    "                        elif 'default' in fee_rates:\n",
    "                            fee_rate = fee_rates['default']\n",
    "                    else:\n",
    "                        # æ•°å€¤ã®å ´åˆï¼ˆæ—§æ—§å½¢å¼ - ã•ã‚‰ãªã‚‹äº’æ›æ€§ã®ãŸã‚ï¼‰\n",
    "                        fee_rate = fee_rates\n",
    "                \n",
    "                return pd.Series([category_name, fee_category, fee_rate, media_fee])\n",
    "            \n",
    "            # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã¨æ‰‹æ•°æ–™ç‡ã‚’åˆ—ã«è¿½åŠ \n",
    "            if 'ã‚«ãƒ†ã‚´ãƒªãƒ¼' in result_df.columns and 'è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡' in result_df.columns:\n",
    "                # applyé–¢æ•°ã§è¤‡æ•°ã®å€¤ã‚’åŒæ™‚ã«è¿”ã™\n",
    "                result_df[['å•†å“æƒ…å ±_ã‚«ãƒ†ã‚´ãƒª', 'è²©å£²æ‰‹æ•°æ–™ã‚«ãƒ†ã‚´ãƒª', 'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_è²©å£²æ‰‹æ•°æ–™ç‡', 'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_ãƒ¡ãƒ‡ã‚£ã‚¢æ‰‹æ•°æ–™']] = (\n",
    "                    result_df.apply(get_category_info_and_fee_rate, axis=1)\n",
    "                )\n",
    "                \n",
    "                # æ‰‹æ•°æ–™ç‡ã‚’ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤ºç”¨ã«å¤‰æ›ï¼ˆä¾‹: 0.15 â†’ 15%ï¼‰\n",
    "                result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_è²©å£²æ‰‹æ•°æ–™ç‡_è¡¨ç¤ºç”¨'] = result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_è²©å£²æ‰‹æ•°æ–™ç‡'].apply(\n",
    "                    lambda x: f\"{x*100:.1f}%\" if pd.notna(x) else \"å¯¾è±¡å¤–\"\n",
    "                )\n",
    "                \n",
    "                # è²©å£²æ‰‹æ•°æ–™ã®è¨ˆç®—ï¼ˆæœ€ä½è²©å£²æ‰‹æ•°æ–™ã‚’è€ƒæ…®ï¼‰\n",
    "                def calculate_fee(row):\n",
    "                    if pd.isna(row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_è²©å£²æ‰‹æ•°æ–™ç‡']) or pd.isna(row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡']):\n",
    "                        return None\n",
    "                    \n",
    "                    category_name = row['å•†å“æƒ…å ±_ã‚«ãƒ†ã‚´ãƒª']\n",
    "                    min_fee = 0\n",
    "                    if category_name in category_mapping:\n",
    "                        min_fee = category_mapping[category_name].get('æœ€ä½è²©å£²æ‰‹æ•°æ–™', 0)\n",
    "                    \n",
    "                    calculated_fee = row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡'] * row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_è²©å£²æ‰‹æ•°æ–™ç‡']\n",
    "                    \n",
    "                    # æœ€ä½æ‰‹æ•°æ–™ãŒnullã®å ´åˆã¯æœ€ä½æ–™é‡‘ã®åˆ¶ç´„ãªã—\n",
    "                    if min_fee is None:\n",
    "                        return calculated_fee\n",
    "                    \n",
    "                    # æœ€ä½æ‰‹æ•°æ–™ã¨è¨ˆç®—æ‰‹æ•°æ–™ã®å¤§ãã„æ–¹ã‚’æ¡ç”¨\n",
    "                    return max(calculated_fee, min_fee)\n",
    "                \n",
    "                # è²©å£²æ‰‹æ•°æ–™ã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ ï¼ˆå°æ•°ç‚¹ç¬¬ä¸€ä½ã§å››æ¨äº”å…¥ï¼‰\n",
    "                result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_è²©å£²æ‰‹æ•°æ–™'] = result_df.apply(calculate_fee, axis=1).apply(\n",
    "                    lambda x: round(x) if pd.notna(x) else None\n",
    "                )\n",
    "                \n",
    "                # è²©å£²æ‰‹æ•°æ–™ï¼ˆç¨è¾¼ï¼‰ã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ ï¼ˆæ‰‹æ•°æ–™ã«10%ã®æ¶ˆè²»ç¨ã‚’åŠ ç®—ã—ã€å°æ•°ç‚¹ç¬¬ä¸€ä½ã§å››æ¨äº”å…¥ï¼‰\n",
    "                result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_è²©å£²æ‰‹æ•°æ–™(ç¨è¾¼)'] = result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_è²©å£²æ‰‹æ•°æ–™'].apply(\n",
    "                    lambda x: round(x * 1.1) if pd.notna(x) else None\n",
    "                )\n",
    "                \n",
    "                logging.info(\"ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã¨è²©å£²æ‰‹æ•°æ–™ç‡ã€ç¨è¾¼æ‰‹æ•°æ–™ã€ãƒ¡ãƒ‡ã‚£ã‚¢æ‰‹æ•°æ–™(ç¨è¾¼)ã®åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"ã‚«ãƒ†ã‚´ãƒªè¨ˆç®—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            traceback.print_exc()  # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å‡ºåŠ›\n",
    "            return df\n",
    "\n",
    "\n",
    "    def add_sourcing_price_calculations(self, df):\n",
    "        \"\"\"\n",
    "        ä»•å…¥ã‚Œæƒ…å ±ï¼ˆãƒãƒƒã‚·ãƒ¼ã€ã‚¹ãƒ¼ãƒ‡ãƒªã€ãƒ¤ãƒ•ãƒ¼ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ï¼‰ã‹ã‚‰\n",
    "        æœ€å®‰å€¤æƒ…å ±ã‚’è¨ˆç®—ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            åˆ—ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ\n",
    "            result_df = df.copy()\n",
    "            \n",
    "            # ä»•å…¥ã‚Œã‚µã‚¤ãƒˆæƒ…å ±ã®è¨­å®š\n",
    "            sourcing_sites = [\n",
    "                {\n",
    "                    'name': 'ãƒãƒƒã‚·ãƒ¼',\n",
    "                    'price_column': 'ãƒãƒƒã‚·ãƒ¼_ä¾¡æ ¼',\n",
    "                    'is_tax_included': False,  # ç¨æŠœãä¾¡æ ¼ã®å ´åˆã¯False\n",
    "                    'url_prefix': 'https://www.netsea.jp/search/?keyword=',\n",
    "                    'url_column': None  # ç‰¹å®šã®URLåˆ—ãŒãªã„å ´åˆã¯None\n",
    "                },\n",
    "                {\n",
    "                    'name': 'ã‚¹ãƒ¼ãƒ‡ãƒª',\n",
    "                    'price_column': 'ã‚¹ãƒ¼ãƒ‡ãƒª_ä¾¡æ ¼',\n",
    "                    'is_tax_included': False,  # ç¨æŠœãä¾¡æ ¼ã®å ´åˆã¯False\n",
    "                    'url_prefix': 'https://www.superdelivery.com/p/do/psl/?so=score&vi=1&sb=all&word=',\n",
    "                    'url_column': None\n",
    "                },\n",
    "                {\n",
    "                    'name': 'ãƒ¤ãƒ•ãƒ¼',\n",
    "                    'price_column': 'ãƒ¤ãƒ•ãƒ¼_ä¾¡æ ¼',\n",
    "                    'is_tax_included': True,  # ç¨è¾¼ã¿ä¾¡æ ¼ã®å ´åˆã¯True\n",
    "                    'url_prefix': '',  # URLåˆ—ã‹ã‚‰ç›´æ¥å–å¾—ã™ã‚‹ã®ã§ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã¯ä¸è¦\n",
    "                    'url_column': 'ãƒ¤ãƒ•ãƒ¼_å•†å“URL'  # ç‰¹å®šã®URLåˆ—ãŒã‚ã‚‹å ´åˆã¯ãã®åˆ—å\n",
    "                }\n",
    "                # å°†æ¥çš„ã«ä»–ã®å¸ã‚µã‚¤ãƒˆã‚’è¿½åŠ ã™ã‚‹å ´åˆã¯ã€ã“ã“ã«è¿½åŠ ã—ã¦ã„ã\n",
    "            ]\n",
    "            \n",
    "            # å„è¡Œã«ã¤ã„ã¦æœ€å®‰å€¤ã¨å¯¾å¿œã™ã‚‹URLã‚’è¨ˆç®—\n",
    "            def find_cheapest_price_and_url(row):\n",
    "                min_price = float('inf')  # åˆæœŸå€¤ã¯ç„¡é™å¤§\n",
    "                min_price_site = None\n",
    "                \n",
    "                for site in sourcing_sites:\n",
    "                    price_column = site['price_column']\n",
    "                    \n",
    "                    # åˆ—ãŒå­˜åœ¨ã—ã€å€¤ãŒã‚ã‚‹å ´åˆã®ã¿å‡¦ç†\n",
    "                    if price_column in row and pd.notna(row[price_column]):\n",
    "                        # ä¾¡æ ¼ã‚’å–å¾—\n",
    "                        price = float(row[price_column])\n",
    "                        \n",
    "                        # ç¨æŠœãä¾¡æ ¼ã®å ´åˆã¯ç¨è¾¼ã¿ã«å¤‰æ›\n",
    "                        if not site['is_tax_included']:\n",
    "                            price = price * 1.1\n",
    "                        \n",
    "                        # æœ€å®‰å€¤ã‚’æ›´æ–°\n",
    "                        if price < min_price:\n",
    "                            min_price = price\n",
    "                            min_price_site = site\n",
    "                \n",
    "                # æœ€å®‰å€¤ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆ\n",
    "                if min_price_site is None:\n",
    "                    return pd.Series([None, None])\n",
    "                \n",
    "                # URLã®ç”Ÿæˆ\n",
    "                url = None\n",
    "                if min_price_site['url_column'] and min_price_site['url_column'] in row:\n",
    "                    # ç‰¹å®šã®URLåˆ—ãŒã‚ã‚‹å ´åˆã¯ãã“ã‹ã‚‰å–å¾—\n",
    "                    url = row[min_price_site['url_column']]\n",
    "                else:\n",
    "                    # URLãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã¨JANã‚³ãƒ¼ãƒ‰ã‚’çµåˆ\n",
    "                    jan_code = row['JAN'] if pd.notna(row['JAN']) else ''\n",
    "                    url = min_price_site['url_prefix'] + str(jan_code)\n",
    "                \n",
    "                return pd.Series([round(min_price), url])\n",
    "            \n",
    "            # æœ€å®‰å€¤ã¨URLã‚’åˆ—ã«è¿½åŠ \n",
    "            if 'JAN' in result_df.columns:\n",
    "                # å„ã‚µã‚¤ãƒˆã®ä¾¡æ ¼åˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª\n",
    "                existing_sites = []\n",
    "                for site in sourcing_sites:\n",
    "                    if site['price_column'] in result_df.columns:\n",
    "                        existing_sites.append(site)\n",
    "                \n",
    "                if existing_sites:\n",
    "                    print(f\"ğŸ“Š ä»•å…¥ã‚Œä¾¡æ ¼è¨ˆç®—: {len(existing_sites)}ã‚µã‚¤ãƒˆã®ä¾¡æ ¼æƒ…å ±ãŒã‚ã‚Šã¾ã™\")\n",
    "                    logging.info(f\"ä»•å…¥ã‚Œä¾¡æ ¼è¨ˆç®—: {len(existing_sites)}ã‚µã‚¤ãƒˆã®ä¾¡æ ¼æƒ…å ±ãŒã‚ã‚Šã¾ã™\")\n",
    "                    \n",
    "                    # ã‚µã‚¤ãƒˆæƒ…å ±ã®è¡¨ç¤º\n",
    "                    for site in existing_sites:\n",
    "                        non_null_count = result_df[site['price_column']].notna().sum()\n",
    "                        print(f\"  - {site['name']}: {non_null_count}ä»¶ã®ä¾¡æ ¼æƒ…å ±\")\n",
    "                    \n",
    "                    # æœ€å®‰å€¤ã¨URLã‚’è¨ˆç®—\n",
    "                    result_df[['JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)', 'JANä¾¡æ ¼_å•†å“URL']] = result_df.apply(\n",
    "                        find_cheapest_price_and_url, axis=1\n",
    "                    )\n",
    "                    \n",
    "                    # è¨ˆç®—çµæœã®çµ±è¨ˆ\n",
    "                    non_null_price = result_df['JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)'].notna().sum()\n",
    "                    print(f\"âœ… JANä¾¡æ ¼è¨ˆç®—å®Œäº†: {non_null_price}ä»¶ã®æœ€å®‰å€¤æƒ…å ±ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "                    logging.info(f\"JANä¾¡æ ¼è¨ˆç®—å®Œäº†: {non_null_price}ä»¶ã®æœ€å®‰å€¤æƒ…å ±ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "                else:\n",
    "                    print(\"âš ï¸ ä»•å…¥ã‚Œä¾¡æ ¼åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "                    logging.warning(\"ä»•å…¥ã‚Œä¾¡æ ¼åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            else:\n",
    "                print(\"âš ï¸ JANåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ä»•å…¥ã‚Œä¾¡æ ¼è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
    "                logging.warning(\"JANåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ä»•å…¥ã‚Œä¾¡æ ¼è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
    "            \n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"ä»•å…¥ã‚Œä¾¡æ ¼è¨ˆç®—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()  # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å‡ºåŠ›\n",
    "            return df\n",
    "\n",
    "    def add_yoriyasu_calculations(self, df):\n",
    "        \"\"\"\n",
    "        ãƒ¨ãƒªãƒ¤ã‚¹ã®æƒ…å ±ã‚’å‡¦ç†ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            åˆ—ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ\n",
    "            result_df = df.copy()\n",
    "            \n",
    "            # ãƒ¨ãƒªãƒ¤ã‚¹ã®æƒ…å ±ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª\n",
    "            yoriyasu_columns = [col for col in result_df.columns if col.startswith('ãƒ¨ãƒªãƒ¤ã‚¹_')]\n",
    "            if not yoriyasu_columns:\n",
    "                print(\"âš ï¸ ãƒ¨ãƒªãƒ¤ã‚¹ã®æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "                logging.warning(\"ãƒ¨ãƒªãƒ¤ã‚¹ã®æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "                return result_df\n",
    "            \n",
    "            print(f\"ğŸ“Š ãƒ¨ãƒªãƒ¤ã‚¹æƒ…å ±å‡¦ç†: {len(yoriyasu_columns)}åˆ—ã®æƒ…å ±ãŒã‚ã‚Šã¾ã™\")\n",
    "            \n",
    "            # é€æ–™æƒ…å ±ã«åŸºã¥ã„ã¦ä¾¡æ ¼è¡¨ç¤ºã‚’èª¿æ•´ã™ã‚‹é–¢æ•°\n",
    "            def format_price_with_shipping(price, shipping):\n",
    "                if pd.isna(price) or pd.isna(shipping):\n",
    "                    return None\n",
    "                    \n",
    "                price_str = str(price)\n",
    "                \n",
    "                if shipping == 'é€æ–™ç„¡æ–™':\n",
    "                    return price_str\n",
    "                elif shipping == 'æ¡ä»¶ä»˜ãé€æ–™ç„¡æ–™':\n",
    "                    return f\"{price_str} (â€»)\"\n",
    "                elif shipping == 'é€æ–™åˆ¥':\n",
    "                    return f\"{price_str} (+)\"\n",
    "                else:\n",
    "                    return price_str\n",
    "            \n",
    "            # 4ã¤ã®ä»•å…¥å…ˆæƒ…å ±ã‚’å‡¦ç†\n",
    "            for i in range(1, 5):\n",
    "                # ä¾¡æ ¼åˆ—\n",
    "                price_col = f'ãƒ¨ãƒªãƒ¤ã‚¹_ä»•å…¥ä¾¡æ ¼{i}'\n",
    "                shipping_col = f'ãƒ¨ãƒªãƒ¤ã‚¹_é€æ–™{i}'\n",
    "                url_col = f'ãƒ¨ãƒªãƒ¤ã‚¹_ä»•å…¥ã‚ŒURL{i}'\n",
    "                site_col = f'ãƒ¨ãƒªãƒ¤ã‚¹_ä»•å…¥ã‚Œã‚µã‚¤ãƒˆ{i}'\n",
    "                \n",
    "                # å¯¾å¿œã™ã‚‹å‡ºåŠ›åˆ—\n",
    "                output_price_col = f'ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ä¾¡æ ¼{i}'\n",
    "                output_url_col = f'ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ã‚ŒURL{i}'\n",
    "                output_site_col = f'ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ã‚Œã‚µã‚¤ãƒˆ{i}'\n",
    "                \n",
    "                # ä¾¡æ ¼æƒ…å ±ã®å‡¦ç†\n",
    "                if price_col in result_df.columns and shipping_col in result_df.columns:\n",
    "                    result_df[output_price_col] = result_df.apply(\n",
    "                        lambda row: format_price_with_shipping(row[price_col], row[shipping_col]), \n",
    "                        axis=1\n",
    "                    )\n",
    "                    \n",
    "                    # å€¤ãŒå…¥ã£ã¦ã„ã‚‹è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "                    non_null_count = result_df[output_price_col].notna().sum()\n",
    "                    print(f\"  - ãƒãƒƒãƒˆä¾¡æ ¼{i}: {non_null_count}ä»¶ã®ä¾¡æ ¼æƒ…å ±\")\n",
    "                \n",
    "                # URLæƒ…å ±ã®å‡¦ç†\n",
    "                if url_col in result_df.columns:\n",
    "                    result_df[output_url_col] = result_df[url_col]\n",
    "                \n",
    "                # ã‚µã‚¤ãƒˆæƒ…å ±ã®å‡¦ç†\n",
    "                if site_col in result_df.columns:\n",
    "                    result_df[output_site_col] = result_df[site_col]\n",
    "            \n",
    "            print(f\"âœ… ãƒ¨ãƒªãƒ¤ã‚¹æƒ…å ±å‡¦ç†å®Œäº†: åˆè¨ˆ12åˆ—ã®æƒ…å ±ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"ãƒ¨ãƒªãƒ¤ã‚¹æƒ…å ±å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return df\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cebf8cc-fe9b-4458-8074-8ff3506fce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«5: å·¥ç¨‹3ï¼ˆå·¥ç¨‹1ã¨å·¥ç¨‹2ã®å‡ºåŠ›çµæœã‚’ä½¿ã†)\n",
    "class ProductCalculator(ProductCalculator):\n",
    "    def add_profit_calculations(self, df):\n",
    "        \"\"\"\n",
    "        æ‰‹æ•°æ–™åˆè¨ˆã¨åˆ©ç›Šã«é–¢ã™ã‚‹è¨ˆç®—ã‚’è¡Œã†ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "        å„ç¨®æ‰‹æ•°æ–™ã®åˆè¨ˆã‚„åˆ©ç›Šé¡ã€åˆ©ç›Šç‡ã‚’è¨ˆç®—ã—ã¾ã™\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            åˆ—ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ\n",
    "            result_df = df.copy()\n",
    "            \n",
    "            # æ‰‹æ•°æ–™é–¢é€£ã®åˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª\n",
    "            fee_columns = [\n",
    "                'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_è²©å£²æ‰‹æ•°æ–™(ç¨è¾¼)',\n",
    "                'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_ç™ºé€ä»£è¡Œæ‰‹æ•°æ–™',\n",
    "                'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_ãƒ¡ãƒ‡ã‚£ã‚¢æ‰‹æ•°æ–™',\n",
    "                'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_æœˆé¡ä¿ç®¡æ–™'\n",
    "            ]\n",
    "            \n",
    "            # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹\n",
    "            existing_fee_columns = [col for col in fee_columns if col in result_df.columns]\n",
    "            \n",
    "            if not existing_fee_columns:\n",
    "                logging.warning(\"æ‰‹æ•°æ–™é–¢é€£ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ‰‹æ•°æ–™åˆè¨ˆã¯è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚\")\n",
    "            else:\n",
    "                # æ‰‹æ•°æ–™åˆè¨ˆã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°\n",
    "                def calculate_total_fee(row):\n",
    "                    total = 0\n",
    "                    \n",
    "                    # å„æ‰‹æ•°æ–™ã‚’åˆè¨ˆï¼ˆNoneã®å ´åˆã¯0ã¨ã—ã¦æ‰±ã†ï¼‰\n",
    "                    for col in existing_fee_columns:\n",
    "                        value = row[col]\n",
    "                        if pd.notna(value):\n",
    "                            total += value\n",
    "                    \n",
    "                    return total\n",
    "                \n",
    "                # æ‰‹æ•°æ–™åˆè¨ˆã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ \n",
    "                result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_æ‰‹æ•°æ–™åˆè¨ˆ'] = result_df.apply(calculate_total_fee, axis=1)\n",
    "                logging.info(\"æ‰‹æ•°æ–™åˆè¨ˆã®åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "            # åˆ©ç›Šé¡ã®è¨ˆç®—\n",
    "            if 'è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡' in result_df.columns and 'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_æ‰‹æ•°æ–™åˆè¨ˆ' in result_df.columns:\n",
    "                def calculate_profit(row):\n",
    "                    # è²©å£²ä¾¡æ ¼ã‚’å–å¾—\n",
    "                    selling_price = row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡'] if pd.notna(row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡']) else 0\n",
    "                    \n",
    "                    # æ‰‹æ•°æ–™åˆè¨ˆã‚’å–å¾—\n",
    "                    total_fee = row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_æ‰‹æ•°æ–™åˆè¨ˆ'] if pd.notna(row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_æ‰‹æ•°æ–™åˆè¨ˆ']) else 0\n",
    "                    \n",
    "                    # å®Ÿè³ªæœ€å®‰å€¤ï¼ˆä»•å…¥ã‚Œä¾¡æ ¼ï¼‰ã‚’å–å¾—\n",
    "                    real_cost = 0\n",
    "                    \n",
    "                    # JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)ã‚’ç¢ºèª\n",
    "                    jan_price = None\n",
    "                    if 'JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)' in row and pd.notna(row['JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)']):\n",
    "                        jan_price = float(row['JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)'])\n",
    "                    \n",
    "                    # ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ä¾¡æ ¼1ã‚’ç¢ºèªï¼ˆæœ«å°¾ã®(â€»)ã‚„(+)ã‚’é™¤å»ã—ã¦æ•°å€¤ã«å¤‰æ›ï¼‰\n",
    "                    net_price = None\n",
    "                    if 'ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ä¾¡æ ¼1' in row and pd.notna(row['ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ä¾¡æ ¼1']):\n",
    "                        price_str = str(row['ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ä¾¡æ ¼1'])\n",
    "                        # æ•°å€¤éƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡ºï¼ˆ(â€»)ã‚„(+)ã‚’é™¤å¤–ï¼‰\n",
    "                        import re\n",
    "                        price_match = re.match(r'(\\d+)', price_str)\n",
    "                        if price_match:\n",
    "                            net_price = float(price_match.group(1))\n",
    "                    \n",
    "                    # JANä¾¡æ ¼ã¨ãƒãƒƒãƒˆä¾¡æ ¼ã‚’æ¯”è¼ƒã—ã¦å°ã•ã„æ–¹ï¼ˆå®‰ã„æ–¹ï¼‰ã‚’æ¡ç”¨\n",
    "                    if jan_price is not None and net_price is not None:\n",
    "                        real_cost = min(jan_price, net_price)\n",
    "                    elif jan_price is not None:\n",
    "                        real_cost = jan_price\n",
    "                    elif net_price is not None:\n",
    "                        real_cost = net_price\n",
    "                    \n",
    "                    # æœ€å®‰å€¤ã‚’åˆ—ã«è¿½åŠ ã™ã‚‹ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼å¤‰æ•°\n",
    "                    row['è²©å£²ä¾¡æ ¼_å®Ÿè³ªæœ€å®‰å€¤'] = real_cost\n",
    "                    \n",
    "                    # åˆ©ç›Šé¡ã‚’è¨ˆç®—ï¼ˆè²©å£²ä¾¡æ ¼ - å®Ÿè³ªæœ€å®‰å€¤ - æ‰‹æ•°æ–™åˆè¨ˆï¼‰\n",
    "                    profit = selling_price - real_cost - total_fee\n",
    "                    \n",
    "                    return round(profit)  # å°æ•°ç‚¹ä»¥ä¸‹ã‚’å››æ¨äº”å…¥\n",
    "                \n",
    "                # å®Ÿè³ªæœ€å®‰å€¤ã®åˆ—ã‚’ä½œæˆ\n",
    "                result_df['è²©å£²ä¾¡æ ¼_å®Ÿè³ªæœ€å®‰å€¤'] = 0\n",
    "                \n",
    "                # åˆ©ç›Šé¡ã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ \n",
    "                result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡'] = result_df.apply(calculate_profit, axis=1)\n",
    "                logging.info(\"åˆ©ç›Šé¡ã®åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "                \n",
    "                # å®Ÿè³ªæœ€å®‰å€¤ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª\n",
    "                # ï¼ˆcalculate_profité–¢æ•°å†…ã®å¤‰æ›´ã¯ç›´æ¥çµæœã«åæ˜ ã•ã‚Œãªã„ãŸã‚ï¼‰\n",
    "                result_df['è²©å£²ä¾¡æ ¼_å®Ÿè³ªæœ€å®‰å€¤'] = result_df.apply(\n",
    "                    lambda row: self._calculate_real_cost(row), axis=1\n",
    "                )\n",
    "                logging.info(\"å®Ÿè³ªæœ€å®‰å€¤ã®åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "            # åˆ©ç›Šç‡ã®è¨ˆç®—\n",
    "            if 'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡' in result_df.columns and 'è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡' in result_df.columns:\n",
    "                def calculate_profit_rate(row):\n",
    "                    # åˆ©ç›Šé¡ã‚’å–å¾—\n",
    "                    profit = row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡'] if pd.notna(row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡']) else 0\n",
    "                    \n",
    "                    # è²©å£²ä¾¡æ ¼ã‚’å–å¾—\n",
    "                    selling_price = row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡'] if pd.notna(row['è²©å£²ä¾¡æ ¼_è¨­å®šè²©å£²é¡']) else 0\n",
    "                    \n",
    "                    # ã‚¼ãƒ­é™¤ç®—ã‚’é˜²ã\n",
    "                    if selling_price == 0:\n",
    "                        return None\n",
    "                    \n",
    "                    # åˆ©ç›Šç‡ã‚’è¨ˆç®—ï¼ˆåˆ©ç›Šé¡ Ã· è²©å£²ä¾¡æ ¼ Ã— 100ï¼‰\n",
    "                    profit_rate = (profit / selling_price) * 100\n",
    "                    \n",
    "                    # å°æ•°ç‚¹ç¬¬ä¸€ä½ã¾ã§ä¸¸ã‚ã¦è¿”ã™ï¼ˆä¾‹: 12.3%ï¼‰\n",
    "                    return round(profit_rate, 1)\n",
    "                \n",
    "                # åˆ©ç›Šç‡ã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ \n",
    "                result_df['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šç‡'] = result_df.apply(calculate_profit_rate, axis=1)\n",
    "                logging.info(\"åˆ©ç›Šç‡ã®åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"åˆ©ç›Šè¨ˆç®—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()  # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å‡ºåŠ›\n",
    "            return df\n",
    "    \n",
    "    def _calculate_real_cost(self, row):\n",
    "        \"\"\"\n",
    "        å®Ÿè³ªæœ€å®‰å€¤ï¼ˆä»•å…¥ã‚Œä¾¡æ ¼ï¼‰ã‚’è¨ˆç®—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        row : pandas.Series\n",
    "            ãƒ‡ãƒ¼ã‚¿è¡Œ\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            å®Ÿè³ªæœ€å®‰å€¤\n",
    "        \"\"\"\n",
    "        # JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)ã‚’ç¢ºèª\n",
    "        jan_price = None\n",
    "        if 'JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)' in row and pd.notna(row['JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)']):\n",
    "            jan_price = float(row['JANä¾¡æ ¼_JANä¾¡æ ¼ä¸‹ä»£(ç¨è¾¼)'])\n",
    "        \n",
    "        # ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ä¾¡æ ¼1ã‚’ç¢ºèªï¼ˆæœ«å°¾ã®(â€»)ã‚„(+)ã‚’é™¤å»ã—ã¦æ•°å€¤ã«å¤‰æ›ï¼‰\n",
    "        net_price = None\n",
    "        if 'ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ä¾¡æ ¼1' in row and pd.notna(row['ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ä¾¡æ ¼1']):\n",
    "            price_str = str(row['ãƒãƒƒãƒˆä¾¡æ ¼_ä»•å…¥ä¾¡æ ¼1'])\n",
    "            # æ•°å€¤éƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡ºï¼ˆ(â€»)ã‚„(+)ã‚’é™¤å¤–ï¼‰\n",
    "            import re\n",
    "            price_match = re.match(r'(\\d+)', price_str)\n",
    "            if price_match:\n",
    "                net_price = float(price_match.group(1))\n",
    "        \n",
    "        # JANä¾¡æ ¼ã¨ãƒãƒƒãƒˆä¾¡æ ¼ã‚’æ¯”è¼ƒã—ã¦å°ã•ã„æ–¹ï¼ˆå®‰ã„æ–¹ï¼‰ã‚’æ¡ç”¨\n",
    "        if jan_price is not None and net_price is not None:\n",
    "            return min(jan_price, net_price)\n",
    "        elif jan_price is not None:\n",
    "            return jan_price\n",
    "        elif net_price is not None:\n",
    "            return net_price\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def add_expected_sales_calculations(self, df):\n",
    "        \"\"\"\n",
    "        æœŸå¾…è²©å£²æ•°ã¨æœŸå¾…åˆ©ç›Šã«é–¢ã™ã‚‹è¨ˆç®—ã‚’è¡Œã†ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "        æœŸå¾…è²©å£²æ•°ã‚„æœŸå¾…åˆ©ç›Šã‚’è¨ˆç®—ã—ã¾ã™\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            åˆ—ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ\n",
    "            result_df = df.copy()\n",
    "            \n",
    "            # æœŸå¾…è²©å£²æ•°(1ãƒ¶æœˆ)ã®è¨ˆç®—\n",
    "            if '30æ—¥é–“_æ–°å“è²©å£²æ•°' in result_df.columns and 'FBAæ•°' in result_df.columns:\n",
    "                def calculate_expected_sales(row):\n",
    "                    # æœˆé–“è²©å£²æ•°ã‚’å–å¾—\n",
    "                    monthly_sales = row['30æ—¥é–“_æ–°å“è²©å£²æ•°'] if pd.notna(row['30æ—¥é–“_æ–°å“è²©å£²æ•°']) else 0\n",
    "                    \n",
    "                    # FBAå‡ºå“è€…æ•°ã‚’å–å¾—\n",
    "                    fba_sellers = row['FBAæ•°'] if pd.notna(row['FBAæ•°']) else 0\n",
    "                    \n",
    "                    # æœŸå¾…è²©å£²æ•°ã‚’è¨ˆç®—ï¼ˆæœˆé–“è²©å£²æ•° Ã· (FBAå‡ºå“è€…æ•° + 1)ï¼‰\n",
    "                    # ã‚¼ãƒ­é™¤ç®—ã‚’é˜²ããŸã‚ã€åˆ†æ¯ãŒ0ã®å ´åˆã¯0ã‚’è¿”ã™\n",
    "                    if fba_sellers + 1 == 0:\n",
    "                        return 0\n",
    "                    \n",
    "                    expected_sales = monthly_sales / (fba_sellers + 1)\n",
    "                    \n",
    "                    # æ•´æ•°ã«å››æ¨äº”å…¥\n",
    "                    return round(expected_sales)\n",
    "                \n",
    "                # æœŸå¾…è²©å£²æ•°ã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ \n",
    "                result_df['æœŸå¾…è²©å£²æ•°ãƒ»åˆ©ç›Š_è²©å£²æœŸå¾…æ•°(1ãƒ¶æœˆ)'] = result_df.apply(calculate_expected_sales, axis=1)\n",
    "                logging.info(\"æœŸå¾…è²©å£²æ•°(1ãƒ¶æœˆ)ã®åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            else:\n",
    "                # å¿…è¦ãªåˆ—ãŒãªã„å ´åˆã¯ãƒ­ã‚°ã«è¨˜éŒ²\n",
    "                missing_columns = []\n",
    "                if '30æ—¥é–“_æ–°å“è²©å£²æ•°' not in result_df.columns:\n",
    "                    missing_columns.append('30æ—¥é–“_æ–°å“è²©å£²æ•°')\n",
    "                if 'FBAæ•°' not in result_df.columns:\n",
    "                    missing_columns.append('FBAæ•°')\n",
    "                \n",
    "                logging.warning(f\"æœŸå¾…è²©å£²æ•°ã®è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {', '.join(missing_columns)}\")\n",
    "                print(f\"âš ï¸ æœŸå¾…è²©å£²æ•°ã®è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {', '.join(missing_columns)}\")\n",
    "            \n",
    "            # æœŸå¾…åˆ©ç›Š(1ãƒ¶æœˆ)ã®è¨ˆç®—\n",
    "            if 'æœŸå¾…è²©å£²æ•°ãƒ»åˆ©ç›Š_è²©å£²æœŸå¾…æ•°(1ãƒ¶æœˆ)' in result_df.columns and 'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡' in result_df.columns:\n",
    "                def calculate_expected_profit_1month(row):\n",
    "                    # æœŸå¾…è²©å£²æ•°ã‚’å–å¾—\n",
    "                    expected_sales = row['æœŸå¾…è²©å£²æ•°ãƒ»åˆ©ç›Š_è²©å£²æœŸå¾…æ•°(1ãƒ¶æœˆ)'] if pd.notna(row['æœŸå¾…è²©å£²æ•°ãƒ»åˆ©ç›Š_è²©å£²æœŸå¾…æ•°(1ãƒ¶æœˆ)']) else 0\n",
    "                    \n",
    "                    # åˆ©ç›Šé¡ã‚’å–å¾—\n",
    "                    profit = row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡'] if pd.notna(row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡']) else 0\n",
    "                    \n",
    "                    # æœŸå¾…åˆ©ç›Šã‚’è¨ˆç®—ï¼ˆæœŸå¾…è²©å£²æ•° Ã— åˆ©ç›Šé¡ï¼‰\n",
    "                    expected_profit = expected_sales * profit\n",
    "                    \n",
    "                    # æ•´æ•°ã«å››æ¨äº”å…¥\n",
    "                    return round(expected_profit)\n",
    "                \n",
    "                # æœŸå¾…åˆ©ç›Š(1ãƒ¶æœˆ)ã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ \n",
    "                result_df['æœŸå¾…è²©å£²æ•°ãƒ»åˆ©ç›Š_æœŸå¾…åˆ©ç›Š(1ãƒ¶æœˆ)'] = result_df.apply(calculate_expected_profit_1month, axis=1)\n",
    "                logging.info(\"æœŸå¾…åˆ©ç›Š(1ãƒ¶æœˆ)ã®åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            else:\n",
    "                logging.warning(\"æœŸå¾…åˆ©ç›Š(1ãƒ¶æœˆ)ã®è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            \n",
    "            # æœŸå¾…åˆ©ç›Š(3ãƒ¶æœˆ)ã®è¨ˆç®—\n",
    "            if '90æ—¥é–“_æ–°å“è²©å£²æ•°' in result_df.columns and 'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡' in result_df.columns:\n",
    "                def calculate_expected_profit_3month(row):\n",
    "                    # 3ãƒ¶æœˆã®è²©å£²æ•°ã‚’å–å¾—\n",
    "                    sales_3month = row['90æ—¥é–“_æ–°å“è²©å£²æ•°'] if pd.notna(row['90æ—¥é–“_æ–°å“è²©å£²æ•°']) else 0\n",
    "                    \n",
    "                    # æœŸå¾…è²©å£²æ•°(3ãƒ¶æœˆ)ã‚’è¨ˆç®—\n",
    "                    # 3ãƒ¶æœˆå…ˆã¯å‡ºå“è€…æ•°ã®å¢—æ¸›ãŒäºˆæ¸¬å›°é›£ãªãŸã‚ã€å¹³å‡çš„ãªå‡ºå“è€…æ•°ã¨ã—ã¦4ã‚’ä½¿ç”¨\n",
    "                    # ã“ã‚Œã¯çµŒé¨“å‰‡ã«åŸºã¥ãã€å¤šãã®å•†å“ãŒ3ãƒ¶æœˆå¾Œã«ç´„4äººã®å‡ºå“è€…ã«è½ã¡ç€ãã¨ã„ã†æƒ³å®šã«ã‚ˆã‚‹\n",
    "                    # (æ–°é›·ç¥ã®ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰è¨ˆç®—ã™ã‚‹ã¨3ãƒ¶æœˆã®æœŸå¾…åˆ©ç›Šã®è¨ˆç®—æ™‚ã®å‡ºå“è€…æ•°ã¯4äºº [3äººï¼‹è‡ªåˆ†] ã§å›ºå®šã—ã¦ã„ãŸ)\n",
    "                    expected_sales_3month = sales_3month / 4\n",
    "                    \n",
    "                    # åˆ©ç›Šé¡ã‚’å–å¾—\n",
    "                    profit = row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡'] if pd.notna(row['æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡']) else 0\n",
    "                    \n",
    "                    # æœŸå¾…åˆ©ç›Šã‚’è¨ˆç®—ï¼ˆæœŸå¾…è²©å£²æ•°(3ãƒ¶æœˆ) Ã— åˆ©ç›Šé¡ï¼‰\n",
    "                    expected_profit = expected_sales_3month * profit\n",
    "                    \n",
    "                    # æ•´æ•°ã«å››æ¨äº”å…¥\n",
    "                    return round(expected_profit)\n",
    "                \n",
    "                # æœŸå¾…åˆ©ç›Š(3ãƒ¶æœˆ)ã‚’è¨ˆç®—ã—ã¦åˆ—ã«è¿½åŠ \n",
    "                result_df['æœŸå¾…è²©å£²æ•°ãƒ»åˆ©ç›Š_æœŸå¾…åˆ©ç›Š(3ãƒ¶æœˆ)'] = result_df.apply(calculate_expected_profit_3month, axis=1)\n",
    "                logging.info(\"æœŸå¾…åˆ©ç›Š(3ãƒ¶æœˆ)ã®åˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "            else:\n",
    "                missing_columns = []\n",
    "                if '90æ—¥é–“_æ–°å“è²©å£²æ•°' not in result_df.columns:\n",
    "                    missing_columns.append('90æ—¥é–“_æ–°å“è²©å£²æ•°')\n",
    "                if 'æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡' not in result_df.columns:\n",
    "                    missing_columns.append('æ‰‹æ•°æ–™ãƒ»åˆ©ç›Š_åˆ©ç›Šé¡')\n",
    "                \n",
    "                logging.warning(f\"æœŸå¾…åˆ©ç›Š(3ãƒ¶æœˆ)ã®è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {', '.join(missing_columns)}\")\n",
    "            \n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"æœŸå¾…è²©å£²æ•°ãƒ»åˆ©ç›Šè¨ˆç®—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            traceback.print_exc()  # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å‡ºåŠ›\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af0a50-a7e6-4cf1-911c-a0b3c70a1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«6: ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Ÿè¡Œ\n",
    "class ProductCalculator(ProductCalculator):\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’å®Ÿè¡Œ\n",
    "        \n",
    "        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€è¨ˆç®—å‡¦ç†ã‚’è¡Œã„ã€çµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"è¨ˆç®—å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™\")\n",
    "            \n",
    "            # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "            df = self.load_data()\n",
    "            \n",
    "            # åˆ—åã®ç¢ºèª\n",
    "            logging.info(f\"å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®åˆ—: {', '.join(df.columns)}\")\n",
    "            \n",
    "            # å·¥ç¨‹1: åŸºæœ¬çš„ãªè¨ˆç®—å‡¦ç†\n",
    "            result_df = self.add_calculation_columns(df)\n",
    "            \n",
    "            # å·¥ç¨‹2-1: ã‚µã‚¤ã‚ºè¨ˆç®—å‡¦ç†\n",
    "            result_df = self.add_size_calculations(result_df)\n",
    "    \n",
    "            # å·¥ç¨‹2-2: ã‚«ãƒ†ã‚´ãƒªè¨ˆç®—å‡¦ç†\n",
    "            result_df = self.add_category_calculations(result_df)\n",
    "            \n",
    "            # å·¥ç¨‹2-3-1: ä»•å…¥ã‚Œä¾¡æ ¼è¨ˆç®—å‡¦ç†ï¼ˆãƒãƒƒã‚·ãƒ¼ã€ã‚¹ãƒ¼ãƒ‡ãƒªã€ãƒ¤ãƒ•ãƒ¼ï¼‰\n",
    "            result_df = self.add_sourcing_price_calculations(result_df)\n",
    "            \n",
    "            # å·¥ç¨‹2-3-2: ãƒ¨ãƒªãƒ¤ã‚¹æƒ…å ±å‡¦ç†\n",
    "            result_df = self.add_yoriyasu_calculations(result_df)\n",
    "            \n",
    "            # å·¥ç¨‹3-1: æ‰‹æ•°æ–™åˆè¨ˆãƒ»åˆ©ç›Šè¨ˆç®—å‡¦ç†\n",
    "            result_df = self.add_profit_calculations(result_df)\n",
    "            \n",
    "            # å·¥ç¨‹3-2: æœŸå¾…è²©å£²æ•°ãƒ»æœŸå¾…åˆ©ç›Šè¨ˆç®—å‡¦ç†\n",
    "            result_df = self.add_expected_sales_calculations(result_df)\n",
    "            \n",
    "            # ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜\n",
    "            self.save_data(result_df)\n",
    "            \n",
    "            # å‡¦ç†çµæœã®æ¦‚è¦ã‚’è¡¨ç¤º\n",
    "            self.print_summary(df, result_df)\n",
    "            \n",
    "            logging.info(\"è¨ˆç®—å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ\")\n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"å‡¦ç†å…¨ä½“ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def print_summary(self, original_df, result_df):\n",
    "        \"\"\"\n",
    "        å‡¦ç†çµæœã®æ¦‚è¦ã‚’è¡¨ç¤º\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        original_df : pandas.DataFrame\n",
    "            å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        result_df : pandas.DataFrame\n",
    "            å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        \"\"\"\n",
    "        # ä»•å…¥ã‚Œã‚½ãƒ¼ã‚¹åˆ—ã‚’é™¤å¤–ã—ãŸè¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ\n",
    "        display_df = result_df.copy()\n",
    "        columns_to_drop = [col for col in display_df.columns if \n",
    "                         col.startswith('ãƒãƒƒã‚·ãƒ¼_') or \n",
    "                         col.startswith('ã‚¹ãƒ¼ãƒ‡ãƒª_') or \n",
    "                         col.startswith('ãƒ¤ãƒ•ãƒ¼_') or \n",
    "                         col.startswith('ãƒ¨ãƒªãƒ¤ã‚¹_')]\n",
    "        \n",
    "        if columns_to_drop:\n",
    "            display_df = display_df.drop(columns=columns_to_drop)\n",
    "            print(f\"â„¹ï¸ è¡¨ç¤ºã‹ã‚‰{len(columns_to_drop)}åˆ—ã®ä»•å…¥ã‚Œã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ã¾ã—ãŸ\")\n",
    "        \n",
    "        # è¿½åŠ ã•ã‚ŒãŸåˆ—ï¼ˆä»•å…¥ã‚Œã‚½ãƒ¼ã‚¹åˆ—ã‚’é™¤ãï¼‰\n",
    "        new_columns = [col for col in display_df.columns if col not in original_df.columns]\n",
    "        \n",
    "        print(\"\\n=== å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼ ===\")\n",
    "        print(f\"ãƒ»å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: {len(original_df)}è¡Œ, {len(original_df.columns)}åˆ—\")\n",
    "        print(f\"ãƒ»å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿: {len(display_df)}è¡Œ, {len(display_df.columns)}åˆ—\")\n",
    "        print(f\"ãƒ»è¿½åŠ ã•ã‚ŒãŸåˆ—: {len(new_columns)}åˆ—\")\n",
    "        \n",
    "        if new_columns:\n",
    "            print(\"\\nè¿½åŠ ã•ã‚ŒãŸåˆ—ã®ä¸€è¦§:\")\n",
    "            for col in new_columns:\n",
    "                print(f\"ãƒ»{col}\")\n",
    "        \n",
    "        print(f\"\\nâœ¨ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "        \n",
    "        # å‡¦ç†çµæœã®ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦display_dfã‚’è¿”ã™\n",
    "        return display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28ef8b-4ba0-4714-b990-fa35a4dbd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«7: å®Ÿè¡Œã‚³ãƒ¼ãƒ‰\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # è¨ˆç®—å‡¦ç†ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ\n",
    "        calculator = ProductCalculator()\n",
    "        \n",
    "        # å‡¦ç†ã‚’å®Ÿè¡Œ\n",
    "        result_df = calculator.process()\n",
    "        \n",
    "        # å‡¦ç†çµæœã®æœ€åˆã®æ•°è¡Œã‚’è¡¨ç¤ºï¼ˆprint_summaryã‹ã‚‰è¿”ã•ã‚Œã‚‹è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½¿ç”¨ï¼‰\n",
    "        display_df = calculator.print_summary(calculator.load_data(), result_df)\n",
    "        \n",
    "        print(\"\\n=== å‡¦ç†çµæœã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®5è¡Œï¼‰===\")\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.max_rows', 5)\n",
    "        pd.set_option('display.width', None)\n",
    "        display(display_df.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1997fc5-bca5-4cd2-82be-9ed53da5ed3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68a4d0-7a5d-4933-9039-86de50ba77a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182069bc-30d0-4688-9b2e-aa66a3fa5089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
